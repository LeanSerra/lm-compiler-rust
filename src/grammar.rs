/// Generated by rustemo. Do not edit manually!
use std::fmt::Debug;
use std::hash::Hash;
use rustemo::{
    Result, Input as InputT, Lexer, Token, TokenRecognizer as TokenRecognizerT, Parser,
    ParserDefinition, State as StateT, Builder,
};
use rustemo::LRBuilder;
use super::grammar_actions;
use rustemo::{LRParser, LRContext};
use rustemo::Action::{self, Shift, Reduce, Accept};
#[allow(unused_imports)]
use rustemo::debug::{log, logn};
#[allow(unused_imports)]
#[cfg(debug_assertions)]
use rustemo::colored::*;
pub type Input = str;
const STATE_COUNT: usize = 33usize;
const MAX_RECOGNIZERS: usize = 3usize;
#[allow(dead_code)]
const TERMINAL_COUNT: usize = 35usize;
#[allow(clippy::upper_case_acronyms)]
#[derive(Debug, Default, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub enum TokenKind {
    #[default]
    STOP,
    TokenInt,
    TokenFloat,
    TokenString,
    TokenIntLiteral,
    TokenFloatLiteral,
    TokenStringLiteral,
    TokenId,
    TokenAssign,
    TokenSum,
    TokenMul,
    TokenSub,
    TokenDiv,
    TokenParOpen,
    TokenParClose,
    TokenCBOpen,
    TokenCBClose,
    TokenSemicolon,
    TokenColon,
    TokenInit,
    TokenWhile,
    TokenEqual,
    TokenNotEqual,
    TokenLess,
    TokenLessEqual,
    TokenGreater,
    TokenGreaterEqual,
    TokenTrue,
    TokenFalse,
    TokenIf,
    TokenElse,
    TokenComa,
    TokenAnd,
    TokenOr,
    TokenNot,
}
use TokenKind as TK;
impl From<TokenKind> for usize {
    fn from(t: TokenKind) -> Self {
        t as usize
    }
}
#[allow(clippy::enum_variant_names)]
#[derive(Clone, Copy, PartialEq)]
pub enum ProdKind {
    ProgramP1,
    BodyP1,
    BodyP2,
    BodyP3,
    InitBodyP1,
    VarDeclarationsP1,
    VarDeclarationsP2,
    VarDeclarationP1,
    VarDeclarationP2,
    ExpressionsP1,
    ExpressionsP2,
    ExpressionP1,
    AssignmentP1,
    LiteralP1,
    LiteralP2,
    LiteralP3,
    Data_TypeP1,
    Data_TypeP2,
    Data_TypeP3,
    WhileLoopP1,
    ConditionP1,
    ConditionP2,
    ConditionP3,
    ConditionP4,
    ConjunctionP1,
    ConjunctionP2,
    ComparisonOpP1,
    ComparisonOpP2,
    ComparisonOpP3,
    ComparisonOpP4,
    ComparisonOpP5,
    ComparisonOpP6,
    IfP1,
    ElseP1,
    ArithmeticOperationP1,
    ArithmeticOperationP2,
    ArithmeticOperationP3,
    ArithmeticOperationP4,
    NumberP1,
    NumberP2,
    ArithmeticOperatorP1,
    ArithmeticOperatorP2,
    ArithmeticOperatorP3,
    ArithmeticOperatorP4,
    NotP1,
}
use ProdKind as PK;
impl std::fmt::Debug for ProdKind {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let name = match self {
            ProdKind::ProgramP1 => {
                "Program: TokenId TokenParOpen TokenParClose TokenCBOpen Body TokenCBClose"
            }
            ProdKind::BodyP1 => "Body: TokenInit InitBody Expressions",
            ProdKind::BodyP2 => "Body: TokenInit InitBody",
            ProdKind::BodyP3 => "Body: ",
            ProdKind::InitBodyP1 => "InitBody: TokenCBOpen VarDeclarations TokenCBClose",
            ProdKind::VarDeclarationsP1 => "VarDeclarations: VarDeclaration",
            ProdKind::VarDeclarationsP2 => {
                "VarDeclarations: VarDeclaration VarDeclarations"
            }
            ProdKind::VarDeclarationP1 => "VarDeclaration: TokenId TokenColon Data_Type",
            ProdKind::VarDeclarationP2 => {
                "VarDeclaration: TokenId TokenComa VarDeclaration"
            }
            ProdKind::ExpressionsP1 => "Expressions: Expression",
            ProdKind::ExpressionsP2 => "Expressions: Expression Expressions",
            ProdKind::ExpressionP1 => "Expression: Assignment",
            ProdKind::AssignmentP1 => "Assignment: TokenId TokenAssign Literal",
            ProdKind::LiteralP1 => "Literal: TokenIntLiteral",
            ProdKind::LiteralP2 => "Literal: TokenFloatLiteral",
            ProdKind::LiteralP3 => "Literal: TokenStringLiteral",
            ProdKind::Data_TypeP1 => "Data_Type: TokenInt",
            ProdKind::Data_TypeP2 => "Data_Type: TokenFloat",
            ProdKind::Data_TypeP3 => "Data_Type: TokenString",
            ProdKind::WhileLoopP1 => {
                "WhileLoop: TokenWhile TokenParOpen Condition TokenParClose TokenCBOpen Body TokenCBClose"
            }
            ProdKind::ConditionP1 => "Condition: Expression ComparisonOp Expression",
            ProdKind::ConditionP2 => "Condition: TokenTrue",
            ProdKind::ConditionP3 => "Condition: TokenFalse",
            ProdKind::ConditionP4 => {
                "Condition: Expression ComparisonOp Expression Conjunction Condition"
            }
            ProdKind::ConjunctionP1 => "Conjunction: TokenAnd",
            ProdKind::ConjunctionP2 => "Conjunction: TokenOr",
            ProdKind::ComparisonOpP1 => "ComparisonOp: TokenEqual",
            ProdKind::ComparisonOpP2 => "ComparisonOp: TokenNotEqual",
            ProdKind::ComparisonOpP3 => "ComparisonOp: TokenLess",
            ProdKind::ComparisonOpP4 => "ComparisonOp: TokenLessEqual",
            ProdKind::ComparisonOpP5 => "ComparisonOp: TokenGreater",
            ProdKind::ComparisonOpP6 => "ComparisonOp: TokenGreaterEqual",
            ProdKind::IfP1 => {
                "If: TokenIf TokenParOpen Condition TokenParClose TokenCBOpen Body TokenCBClose"
            }
            ProdKind::ElseP1 => "Else: TokenElse TokenCBOpen Body TokenCBClose",
            ProdKind::ArithmeticOperationP1 => {
                "ArithmeticOperation: TokenId ArithmeticOperator TokenId"
            }
            ProdKind::ArithmeticOperationP2 => {
                "ArithmeticOperation: TokenId ArithmeticOperator Number"
            }
            ProdKind::ArithmeticOperationP3 => {
                "ArithmeticOperation: Number ArithmeticOperator TokenId"
            }
            ProdKind::ArithmeticOperationP4 => {
                "ArithmeticOperation: Number ArithmeticOperator Number"
            }
            ProdKind::NumberP1 => "Number: TokenIntLiteral",
            ProdKind::NumberP2 => "Number: TokenFloatLiteral",
            ProdKind::ArithmeticOperatorP1 => "ArithmeticOperator: TokenSum",
            ProdKind::ArithmeticOperatorP2 => "ArithmeticOperator: TokenMul",
            ProdKind::ArithmeticOperatorP3 => "ArithmeticOperator: TokenSub",
            ProdKind::ArithmeticOperatorP4 => "ArithmeticOperator: TokenDiv",
            ProdKind::NotP1 => "Not: TokenNot Condition",
        };
        write!(f, "{name}")
    }
}
#[allow(clippy::upper_case_acronyms)]
#[allow(dead_code)]
#[derive(Clone, Copy, Debug)]
pub enum NonTermKind {
    EMPTY,
    AUG,
    Program,
    Body,
    InitBody,
    VarDeclarations,
    VarDeclaration,
    Expressions,
    Expression,
    Assignment,
    Literal,
    Data_Type,
    WhileLoop,
    Condition,
    Conjunction,
    ComparisonOp,
    If,
    Else,
    ArithmeticOperation,
    Number,
    ArithmeticOperator,
    Not,
}
impl From<ProdKind> for NonTermKind {
    fn from(prod: ProdKind) -> Self {
        match prod {
            ProdKind::ProgramP1 => NonTermKind::Program,
            ProdKind::BodyP1 => NonTermKind::Body,
            ProdKind::BodyP2 => NonTermKind::Body,
            ProdKind::BodyP3 => NonTermKind::Body,
            ProdKind::InitBodyP1 => NonTermKind::InitBody,
            ProdKind::VarDeclarationsP1 => NonTermKind::VarDeclarations,
            ProdKind::VarDeclarationsP2 => NonTermKind::VarDeclarations,
            ProdKind::VarDeclarationP1 => NonTermKind::VarDeclaration,
            ProdKind::VarDeclarationP2 => NonTermKind::VarDeclaration,
            ProdKind::ExpressionsP1 => NonTermKind::Expressions,
            ProdKind::ExpressionsP2 => NonTermKind::Expressions,
            ProdKind::ExpressionP1 => NonTermKind::Expression,
            ProdKind::AssignmentP1 => NonTermKind::Assignment,
            ProdKind::LiteralP1 => NonTermKind::Literal,
            ProdKind::LiteralP2 => NonTermKind::Literal,
            ProdKind::LiteralP3 => NonTermKind::Literal,
            ProdKind::Data_TypeP1 => NonTermKind::Data_Type,
            ProdKind::Data_TypeP2 => NonTermKind::Data_Type,
            ProdKind::Data_TypeP3 => NonTermKind::Data_Type,
            ProdKind::WhileLoopP1 => NonTermKind::WhileLoop,
            ProdKind::ConditionP1 => NonTermKind::Condition,
            ProdKind::ConditionP2 => NonTermKind::Condition,
            ProdKind::ConditionP3 => NonTermKind::Condition,
            ProdKind::ConditionP4 => NonTermKind::Condition,
            ProdKind::ConjunctionP1 => NonTermKind::Conjunction,
            ProdKind::ConjunctionP2 => NonTermKind::Conjunction,
            ProdKind::ComparisonOpP1 => NonTermKind::ComparisonOp,
            ProdKind::ComparisonOpP2 => NonTermKind::ComparisonOp,
            ProdKind::ComparisonOpP3 => NonTermKind::ComparisonOp,
            ProdKind::ComparisonOpP4 => NonTermKind::ComparisonOp,
            ProdKind::ComparisonOpP5 => NonTermKind::ComparisonOp,
            ProdKind::ComparisonOpP6 => NonTermKind::ComparisonOp,
            ProdKind::IfP1 => NonTermKind::If,
            ProdKind::ElseP1 => NonTermKind::Else,
            ProdKind::ArithmeticOperationP1 => NonTermKind::ArithmeticOperation,
            ProdKind::ArithmeticOperationP2 => NonTermKind::ArithmeticOperation,
            ProdKind::ArithmeticOperationP3 => NonTermKind::ArithmeticOperation,
            ProdKind::ArithmeticOperationP4 => NonTermKind::ArithmeticOperation,
            ProdKind::NumberP1 => NonTermKind::Number,
            ProdKind::NumberP2 => NonTermKind::Number,
            ProdKind::ArithmeticOperatorP1 => NonTermKind::ArithmeticOperator,
            ProdKind::ArithmeticOperatorP2 => NonTermKind::ArithmeticOperator,
            ProdKind::ArithmeticOperatorP3 => NonTermKind::ArithmeticOperator,
            ProdKind::ArithmeticOperatorP4 => NonTermKind::ArithmeticOperator,
            ProdKind::NotP1 => NonTermKind::Not,
        }
    }
}
#[allow(clippy::enum_variant_names)]
#[derive(Default, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum State {
    #[default]
    AUGS0,
    TokenIdS1,
    ProgramS2,
    TokenParOpenS3,
    TokenParCloseS4,
    TokenCBOpenS5,
    TokenInitS6,
    BodyS7,
    TokenCBOpenS8,
    InitBodyS9,
    TokenCBCloseS10,
    TokenIdS11,
    VarDeclarationsS12,
    VarDeclarationS13,
    TokenIdS14,
    ExpressionsS15,
    ExpressionS16,
    AssignmentS17,
    TokenColonS18,
    TokenComaS19,
    TokenCBCloseS20,
    VarDeclarationsS21,
    TokenAssignS22,
    ExpressionsS23,
    TokenIntS24,
    TokenFloatS25,
    TokenStringS26,
    Data_TypeS27,
    VarDeclarationS28,
    TokenIntLiteralS29,
    TokenFloatLiteralS30,
    TokenStringLiteralS31,
    LiteralS32,
}
impl StateT for State {
    fn default_layout() -> Option<Self> {
        None
    }
}
impl From<State> for usize {
    fn from(s: State) -> Self {
        s as usize
    }
}
impl std::fmt::Debug for State {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let name = match self {
            State::AUGS0 => "0:AUG",
            State::TokenIdS1 => "1:TokenId",
            State::ProgramS2 => "2:Program",
            State::TokenParOpenS3 => "3:TokenParOpen",
            State::TokenParCloseS4 => "4:TokenParClose",
            State::TokenCBOpenS5 => "5:TokenCBOpen",
            State::TokenInitS6 => "6:TokenInit",
            State::BodyS7 => "7:Body",
            State::TokenCBOpenS8 => "8:TokenCBOpen",
            State::InitBodyS9 => "9:InitBody",
            State::TokenCBCloseS10 => "10:TokenCBClose",
            State::TokenIdS11 => "11:TokenId",
            State::VarDeclarationsS12 => "12:VarDeclarations",
            State::VarDeclarationS13 => "13:VarDeclaration",
            State::TokenIdS14 => "14:TokenId",
            State::ExpressionsS15 => "15:Expressions",
            State::ExpressionS16 => "16:Expression",
            State::AssignmentS17 => "17:Assignment",
            State::TokenColonS18 => "18:TokenColon",
            State::TokenComaS19 => "19:TokenComa",
            State::TokenCBCloseS20 => "20:TokenCBClose",
            State::VarDeclarationsS21 => "21:VarDeclarations",
            State::TokenAssignS22 => "22:TokenAssign",
            State::ExpressionsS23 => "23:Expressions",
            State::TokenIntS24 => "24:TokenInt",
            State::TokenFloatS25 => "25:TokenFloat",
            State::TokenStringS26 => "26:TokenString",
            State::Data_TypeS27 => "27:Data_Type",
            State::VarDeclarationS28 => "28:VarDeclaration",
            State::TokenIntLiteralS29 => "29:TokenIntLiteral",
            State::TokenFloatLiteralS30 => "30:TokenFloatLiteral",
            State::TokenStringLiteralS31 => "31:TokenStringLiteral",
            State::LiteralS32 => "32:Literal",
        };
        write!(f, "{name}")
    }
}
#[derive(Debug)]
pub enum Symbol {
    Terminal(Terminal),
    NonTerminal(NonTerminal),
}
#[allow(clippy::upper_case_acronyms)]
#[derive(Debug)]
pub enum Terminal {
    TokenInt(grammar_actions::TokenInt),
    TokenFloat(grammar_actions::TokenFloat),
    TokenString(grammar_actions::TokenString),
    TokenIntLiteral(grammar_actions::TokenIntLiteral),
    TokenFloatLiteral(grammar_actions::TokenFloatLiteral),
    TokenStringLiteral(grammar_actions::TokenStringLiteral),
    TokenId(grammar_actions::TokenId),
    TokenAssign(grammar_actions::TokenAssign),
    TokenParOpen(grammar_actions::TokenParOpen),
    TokenParClose(grammar_actions::TokenParClose),
    TokenCBOpen(grammar_actions::TokenCBOpen),
    TokenCBClose(grammar_actions::TokenCBClose),
    TokenColon(grammar_actions::TokenColon),
    TokenInit(grammar_actions::TokenInit),
    TokenComa(grammar_actions::TokenComa),
}
#[derive(Debug)]
pub enum NonTerminal {
    Program(grammar_actions::Program),
    Body(grammar_actions::Body),
    InitBody(grammar_actions::InitBody),
    VarDeclarations(grammar_actions::VarDeclarations),
    VarDeclaration(grammar_actions::VarDeclaration),
    Expressions(grammar_actions::Expressions),
    Expression(grammar_actions::Expression),
    Assignment(grammar_actions::Assignment),
    Literal(grammar_actions::Literal),
    Data_Type(grammar_actions::Data_Type),
}
type ActionFn = fn(token: TokenKind) -> Vec<Action<State, ProdKind>>;
pub struct GrammarParserDefinition {
    actions: [ActionFn; STATE_COUNT],
    gotos: [fn(nonterm: NonTermKind) -> State; STATE_COUNT],
    token_kinds: [[Option<(TokenKind, bool)>; MAX_RECOGNIZERS]; STATE_COUNT],
}
fn action_aug_s0(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS1)]),
        _ => vec![],
    }
}
fn action_tokenid_s1(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenParOpen => Vec::from(&[Shift(State::TokenParOpenS3)]),
        _ => vec![],
    }
}
fn action_program_s2(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Accept]),
        _ => vec![],
    }
}
fn action_tokenparopen_s3(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenParClose => Vec::from(&[Shift(State::TokenParCloseS4)]),
        _ => vec![],
    }
}
fn action_tokenparclose_s4(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBOpen => Vec::from(&[Shift(State::TokenCBOpenS5)]),
        _ => vec![],
    }
}
fn action_tokencbopen_s5(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Reduce(PK::BodyP3, 0usize)]),
        TK::TokenInit => Vec::from(&[Shift(State::TokenInitS6)]),
        _ => vec![],
    }
}
fn action_tokeninit_s6(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBOpen => Vec::from(&[Shift(State::TokenCBOpenS8)]),
        _ => vec![],
    }
}
fn action_body_s7(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Shift(State::TokenCBCloseS10)]),
        _ => vec![],
    }
}
fn action_tokencbopen_s8(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS11)]),
        _ => vec![],
    }
}
fn action_initbody_s9(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS14)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::BodyP2, 2usize)]),
        _ => vec![],
    }
}
fn action_tokencbclose_s10(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Reduce(PK::ProgramP1, 6usize)]),
        _ => vec![],
    }
}
fn action_tokenid_s11(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenColon => Vec::from(&[Shift(State::TokenColonS18)]),
        TK::TokenComa => Vec::from(&[Shift(State::TokenComaS19)]),
        _ => vec![],
    }
}
fn action_vardeclarations_s12(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Shift(State::TokenCBCloseS20)]),
        _ => vec![],
    }
}
fn action_vardeclaration_s13(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS11)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::VarDeclarationsP1, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenid_s14(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenAssign => Vec::from(&[Shift(State::TokenAssignS22)]),
        _ => vec![],
    }
}
fn action_expressions_s15(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Reduce(PK::BodyP1, 3usize)]),
        _ => vec![],
    }
}
fn action_expression_s16(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS14)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::ExpressionsP1, 1usize)]),
        _ => vec![],
    }
}
fn action_assignment_s17(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::ExpressionP1, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::ExpressionP1, 1usize)]),
        _ => vec![],
    }
}
fn action_tokencolon_s18(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenInt => Vec::from(&[Shift(State::TokenIntS24)]),
        TK::TokenFloat => Vec::from(&[Shift(State::TokenFloatS25)]),
        TK::TokenString => Vec::from(&[Shift(State::TokenStringS26)]),
        _ => vec![],
    }
}
fn action_tokencoma_s19(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS11)]),
        _ => vec![],
    }
}
fn action_tokencbclose_s20(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::InitBodyP1, 3usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::InitBodyP1, 3usize)]),
        _ => vec![],
    }
}
fn action_vardeclarations_s21(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Reduce(PK::VarDeclarationsP2, 2usize)]),
        _ => vec![],
    }
}
fn action_tokenassign_s22(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenIntLiteral => Vec::from(&[Shift(State::TokenIntLiteralS29)]),
        TK::TokenFloatLiteral => Vec::from(&[Shift(State::TokenFloatLiteralS30)]),
        TK::TokenStringLiteral => Vec::from(&[Shift(State::TokenStringLiteralS31)]),
        _ => vec![],
    }
}
fn action_expressions_s23(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Reduce(PK::ExpressionsP2, 2usize)]),
        _ => vec![],
    }
}
fn action_tokenint_s24(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::Data_TypeP1, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::Data_TypeP1, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenfloat_s25(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::Data_TypeP2, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::Data_TypeP2, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenstring_s26(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::Data_TypeP3, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::Data_TypeP3, 1usize)]),
        _ => vec![],
    }
}
fn action_data_type_s27(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::VarDeclarationP1, 3usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::VarDeclarationP1, 3usize)]),
        _ => vec![],
    }
}
fn action_vardeclaration_s28(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::VarDeclarationP2, 3usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::VarDeclarationP2, 3usize)]),
        _ => vec![],
    }
}
fn action_tokenintliteral_s29(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::LiteralP1, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::LiteralP1, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenfloatliteral_s30(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::LiteralP2, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::LiteralP2, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenstringliteral_s31(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::LiteralP3, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::LiteralP3, 1usize)]),
        _ => vec![],
    }
}
fn action_literal_s32(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::AssignmentP1, 3usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::AssignmentP1, 3usize)]),
        _ => vec![],
    }
}
fn goto_aug_s0(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Program => State::ProgramS2,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::AUGS0
            )
        }
    }
}
fn goto_tokencbopen_s5(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Body => State::BodyS7,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenCBOpenS5
            )
        }
    }
}
fn goto_tokeninit_s6(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::InitBody => State::InitBodyS9,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenInitS6
            )
        }
    }
}
fn goto_tokencbopen_s8(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::VarDeclarations => State::VarDeclarationsS12,
        NonTermKind::VarDeclaration => State::VarDeclarationS13,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenCBOpenS8
            )
        }
    }
}
fn goto_initbody_s9(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Expressions => State::ExpressionsS15,
        NonTermKind::Expression => State::ExpressionS16,
        NonTermKind::Assignment => State::AssignmentS17,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::InitBodyS9
            )
        }
    }
}
fn goto_vardeclaration_s13(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::VarDeclarations => State::VarDeclarationsS21,
        NonTermKind::VarDeclaration => State::VarDeclarationS13,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::VarDeclarationS13
            )
        }
    }
}
fn goto_expression_s16(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Expressions => State::ExpressionsS23,
        NonTermKind::Expression => State::ExpressionS16,
        NonTermKind::Assignment => State::AssignmentS17,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::ExpressionS16
            )
        }
    }
}
fn goto_tokencolon_s18(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Data_Type => State::Data_TypeS27,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenColonS18
            )
        }
    }
}
fn goto_tokencoma_s19(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::VarDeclaration => State::VarDeclarationS28,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenComaS19
            )
        }
    }
}
fn goto_tokenassign_s22(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Literal => State::LiteralS32,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenAssignS22
            )
        }
    }
}
fn goto_invalid(_nonterm_kind: NonTermKind) -> State {
    panic!("Invalid GOTO entry!");
}
pub(crate) static PARSER_DEFINITION: GrammarParserDefinition = GrammarParserDefinition {
    actions: [
        action_aug_s0,
        action_tokenid_s1,
        action_program_s2,
        action_tokenparopen_s3,
        action_tokenparclose_s4,
        action_tokencbopen_s5,
        action_tokeninit_s6,
        action_body_s7,
        action_tokencbopen_s8,
        action_initbody_s9,
        action_tokencbclose_s10,
        action_tokenid_s11,
        action_vardeclarations_s12,
        action_vardeclaration_s13,
        action_tokenid_s14,
        action_expressions_s15,
        action_expression_s16,
        action_assignment_s17,
        action_tokencolon_s18,
        action_tokencoma_s19,
        action_tokencbclose_s20,
        action_vardeclarations_s21,
        action_tokenassign_s22,
        action_expressions_s23,
        action_tokenint_s24,
        action_tokenfloat_s25,
        action_tokenstring_s26,
        action_data_type_s27,
        action_vardeclaration_s28,
        action_tokenintliteral_s29,
        action_tokenfloatliteral_s30,
        action_tokenstringliteral_s31,
        action_literal_s32,
    ],
    gotos: [
        goto_aug_s0,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_tokencbopen_s5,
        goto_tokeninit_s6,
        goto_invalid,
        goto_tokencbopen_s8,
        goto_initbody_s9,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_vardeclaration_s13,
        goto_invalid,
        goto_invalid,
        goto_expression_s16,
        goto_invalid,
        goto_tokencolon_s18,
        goto_tokencoma_s19,
        goto_invalid,
        goto_invalid,
        goto_tokenassign_s22,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
    ],
    token_kinds: [
        [Some((TK::TokenId, false)), None, None],
        [Some((TK::TokenParOpen, false)), None, None],
        [Some((TK::STOP, false)), None, None],
        [Some((TK::TokenParClose, false)), None, None],
        [Some((TK::TokenCBOpen, false)), None, None],
        [Some((TK::TokenCBClose, false)), Some((TK::TokenInit, false)), None],
        [Some((TK::TokenCBOpen, false)), None, None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::STOP, false)), None, None],
        [Some((TK::TokenColon, false)), Some((TK::TokenComa, false)), None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenAssign, false)), None, None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [
            Some((TK::TokenInt, false)),
            Some((TK::TokenFloat, false)),
            Some((TK::TokenString, false)),
        ],
        [Some((TK::TokenId, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenCBClose, false)), None, None],
        [
            Some((TK::TokenIntLiteral, false)),
            Some((TK::TokenFloatLiteral, false)),
            Some((TK::TokenStringLiteral, false)),
        ],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
    ],
};
impl ParserDefinition<State, ProdKind, TokenKind, NonTermKind>
for GrammarParserDefinition {
    fn actions(&self, state: State, token: TokenKind) -> Vec<Action<State, ProdKind>> {
        PARSER_DEFINITION.actions[state as usize](token)
    }
    fn goto(&self, state: State, nonterm: NonTermKind) -> State {
        PARSER_DEFINITION.gotos[state as usize](nonterm)
    }
    fn expected_token_kinds(&self, state: State) -> Vec<(TokenKind, bool)> {
        PARSER_DEFINITION.token_kinds[state as usize].iter().map_while(|t| *t).collect()
    }
    fn longest_match() -> bool {
        true
    }
    fn grammar_order() -> bool {
        true
    }
}
pub(crate) type Context<'i, I> = LRContext<'i, I, State, TokenKind>;
pub struct GrammarParser<
    'i,
    I: InputT + ?Sized,
    L: Lexer<'i, Context<'i, I>, State, TokenKind, Input = I>,
    B,
>(
    LRParser<
        'i,
        Context<'i, I>,
        State,
        ProdKind,
        TokenKind,
        NonTermKind,
        GrammarParserDefinition,
        L,
        B,
        I,
    >,
);
#[allow(dead_code)]
impl<'i, L> GrammarParser<'i, Input, L, DefaultBuilder>
where
    L: Lexer<'i, Context<'i, Input>, State, TokenKind, Input = Input>,
{
    pub fn new(lexer: L) -> Self {
        Self(
            LRParser::new(
                &PARSER_DEFINITION,
                State::default(),
                false,
                false,
                lexer,
                DefaultBuilder::new(),
            ),
        )
    }
}
#[allow(dead_code)]
impl<'i, I, L, B> Parser<'i, I, Context<'i, I>, State, TokenKind>
for GrammarParser<'i, I, L, B>
where
    I: InputT + ?Sized + Debug,
    L: Lexer<'i, Context<'i, I>, State, TokenKind, Input = I>,
    B: LRBuilder<'i, I, Context<'i, I>, State, ProdKind, TokenKind>,
{
    type Output = B::Output;
    fn parse(&self, input: &'i I) -> Result<Self::Output> {
        self.0.parse(input)
    }
    fn parse_with_context(
        &self,
        context: &mut Context<'i, I>,
        input: &'i I,
    ) -> Result<Self::Output> {
        self.0.parse_with_context(context, input)
    }
    fn parse_file<'a, F: AsRef<std::path::Path>>(
        &'a mut self,
        file: F,
    ) -> Result<Self::Output>
    where
        'a: 'i,
    {
        self.0.parse_file(file)
    }
}
pub struct DefaultBuilder {
    res_stack: Vec<Symbol>,
}
impl DefaultBuilder {
    #[allow(dead_code)]
    pub fn new() -> Self {
        Self { res_stack: vec![] }
    }
}
impl Builder for DefaultBuilder {
    type Output = grammar_actions::Program;
    fn get_result(&mut self) -> Self::Output {
        match self.res_stack.pop().unwrap() {
            Symbol::NonTerminal(NonTerminal::Program(r)) => r,
            _ => panic!("Invalid result on the parse stack!"),
        }
    }
}
impl<'i> LRBuilder<'i, Input, Context<'i, Input>, State, ProdKind, TokenKind>
for DefaultBuilder {
    #![allow(unused_variables)]
    fn shift_action(
        &mut self,
        context: &Context<'i, Input>,
        token: Token<'i, Input, TokenKind>,
    ) {
        let val = match token.kind {
            TokenKind::STOP => panic!("Cannot shift STOP token!"),
            TokenKind::TokenInt => {
                Terminal::TokenInt(grammar_actions::token_int(context, token))
            }
            TokenKind::TokenFloat => {
                Terminal::TokenFloat(grammar_actions::token_float(context, token))
            }
            TokenKind::TokenString => {
                Terminal::TokenString(grammar_actions::token_string(context, token))
            }
            TokenKind::TokenIntLiteral => {
                Terminal::TokenIntLiteral(
                    grammar_actions::token_int_literal(context, token),
                )
            }
            TokenKind::TokenFloatLiteral => {
                Terminal::TokenFloatLiteral(
                    grammar_actions::token_float_literal(context, token),
                )
            }
            TokenKind::TokenStringLiteral => {
                Terminal::TokenStringLiteral(
                    grammar_actions::token_string_literal(context, token),
                )
            }
            TokenKind::TokenId => {
                Terminal::TokenId(grammar_actions::token_id(context, token))
            }
            TokenKind::TokenAssign => {
                Terminal::TokenAssign(grammar_actions::token_assign(context, token))
            }
            TokenKind::TokenParOpen => {
                Terminal::TokenParOpen(grammar_actions::token_par_open(context, token))
            }
            TokenKind::TokenParClose => {
                Terminal::TokenParClose(grammar_actions::token_par_close(context, token))
            }
            TokenKind::TokenCBOpen => {
                Terminal::TokenCBOpen(grammar_actions::token_cbopen(context, token))
            }
            TokenKind::TokenCBClose => {
                Terminal::TokenCBClose(grammar_actions::token_cbclose(context, token))
            }
            TokenKind::TokenColon => {
                Terminal::TokenColon(grammar_actions::token_colon(context, token))
            }
            TokenKind::TokenInit => {
                Terminal::TokenInit(grammar_actions::token_init(context, token))
            }
            TokenKind::TokenComa => {
                Terminal::TokenComa(grammar_actions::token_coma(context, token))
            }
            _ => panic!("Shift of unreachable terminal!"),
        };
        self.res_stack.push(Symbol::Terminal(val));
    }
    fn reduce_action(
        &mut self,
        context: &Context<'i, Input>,
        prod: ProdKind,
        prod_len: usize,
    ) {
        let prod = match prod {
            ProdKind::ProgramP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 6usize)
                    .into_iter();
                match (
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                ) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenParOpen(p1)),
                        Symbol::Terminal(Terminal::TokenParClose(p2)),
                        Symbol::Terminal(Terminal::TokenCBOpen(p3)),
                        Symbol::NonTerminal(NonTerminal::Body(p4)),
                        Symbol::Terminal(Terminal::TokenCBClose(p5)),
                    ) => {
                        NonTerminal::Program(
                            grammar_actions::program_c1(context, p0, p1, p2, p3, p4, p5),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::BodyP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenInit(p0)),
                        Symbol::NonTerminal(NonTerminal::InitBody(p1)),
                        Symbol::NonTerminal(NonTerminal::Expressions(p2)),
                    ) => NonTerminal::Body(grammar_actions::body_c1(context, p0, p1, p2)),
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::BodyP2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 2usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenInit(p0)),
                        Symbol::NonTerminal(NonTerminal::InitBody(p1)),
                    ) => NonTerminal::Body(grammar_actions::body_c2(context, p0, p1)),
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::BodyP3 => NonTerminal::Body(grammar_actions::body_empty(context)),
            ProdKind::InitBodyP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenCBOpen(p0)),
                        Symbol::NonTerminal(NonTerminal::VarDeclarations(p1)),
                        Symbol::Terminal(Terminal::TokenCBClose(p2)),
                    ) => {
                        NonTerminal::InitBody(
                            grammar_actions::init_body_c1(context, p0, p1, p2),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationsP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::VarDeclaration(p0)) => {
                        NonTerminal::VarDeclarations(
                            grammar_actions::var_declarations_var_declaration(
                                context,
                                p0,
                            ),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationsP2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 2usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::NonTerminal(NonTerminal::VarDeclaration(p0)),
                        Symbol::NonTerminal(NonTerminal::VarDeclarations(p1)),
                    ) => {
                        NonTerminal::VarDeclarations(
                            grammar_actions::var_declarations_c2(context, p0, p1),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenColon(p1)),
                        Symbol::NonTerminal(NonTerminal::Data_Type(p2)),
                    ) => {
                        NonTerminal::VarDeclaration(
                            grammar_actions::var_declaration_c1(context, p0, p1, p2),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationP2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenComa(p1)),
                        Symbol::NonTerminal(NonTerminal::VarDeclaration(p2)),
                    ) => {
                        NonTerminal::VarDeclaration(
                            grammar_actions::var_declaration_c2(context, p0, p1, p2),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::ExpressionsP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::Expression(p0)) => {
                        NonTerminal::Expressions(
                            grammar_actions::expressions_expression(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::ExpressionsP2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 2usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::NonTerminal(NonTerminal::Expression(p0)),
                        Symbol::NonTerminal(NonTerminal::Expressions(p1)),
                    ) => {
                        NonTerminal::Expressions(
                            grammar_actions::expressions_c2(context, p0, p1),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::ExpressionP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::Assignment(p0)) => {
                        NonTerminal::Expression(
                            grammar_actions::expression_assignment(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::AssignmentP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenAssign(p1)),
                        Symbol::NonTerminal(NonTerminal::Literal(p2)),
                    ) => {
                        NonTerminal::Assignment(
                            grammar_actions::assignment_c1(context, p0, p1, p2),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::LiteralP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenIntLiteral(p0)) => {
                        NonTerminal::Literal(
                            grammar_actions::literal_token_int_literal(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::LiteralP2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenFloatLiteral(p0)) => {
                        NonTerminal::Literal(
                            grammar_actions::literal_token_float_literal(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::LiteralP3 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenStringLiteral(p0)) => {
                        NonTerminal::Literal(
                            grammar_actions::literal_token_string_literal(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Data_TypeP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenInt(p0)) => {
                        NonTerminal::Data_Type(
                            grammar_actions::data_type_token_int(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Data_TypeP2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenFloat(p0)) => {
                        NonTerminal::Data_Type(
                            grammar_actions::data_type_token_float(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Data_TypeP3 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenString(p0)) => {
                        NonTerminal::Data_Type(
                            grammar_actions::data_type_token_string(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            _ => panic!("Reduce of unreachable nonterminal!"),
        };
        self.res_stack.push(Symbol::NonTerminal(prod));
    }
}
