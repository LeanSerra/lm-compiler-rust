/// Generated by rustemo. Do not edit manually!
use std::fmt::Debug;
use std::hash::Hash;
use rustemo::{
    Result, Input as InputT, Lexer, Token, TokenRecognizer as TokenRecognizerT, Parser,
    ParserDefinition, State as StateT, Builder,
};
use rustemo::LRBuilder;
use super::grammar_actions;
use rustemo::{LRParser, LRContext};
use rustemo::Action::{self, Shift, Reduce, Accept};
#[allow(unused_imports)]
use rustemo::debug::{log, logn};
#[allow(unused_imports)]
#[cfg(debug_assertions)]
use rustemo::colored::*;
pub type Input = str;
const STATE_COUNT: usize = 31usize;
const MAX_RECOGNIZERS: usize = 3usize;
#[allow(dead_code)]
const TERMINAL_COUNT: usize = 20usize;
#[allow(clippy::upper_case_acronyms)]
#[derive(Debug, Default, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub enum TokenKind {
    #[default]
    STOP,
    TokenInt,
    TokenFloat,
    TokenString,
    TokenIntLiteral,
    TokenFloatLiteral,
    TokenStringLiteral,
    TokenId,
    TokenAssign,
    TokenSum,
    TokenMul,
    TokenSub,
    TokenDiv,
    TokenParOpen,
    TokenParClose,
    TokenCBOpen,
    TokenCBClose,
    TokenSemicolon,
    TokenColon,
    TokenInit,
}
use TokenKind as TK;
impl From<TokenKind> for usize {
    fn from(t: TokenKind) -> Self {
        t as usize
    }
}
#[allow(clippy::enum_variant_names)]
#[derive(Clone, Copy, PartialEq)]
pub enum ProdKind {
    ProgramP1,
    BodyP1,
    InitBodyP1,
    VarDeclarationsP1,
    VarDeclarationsP2,
    VarDeclarationP1,
    ExpressionsP1,
    ExpressionsP2,
    ExpressionP1,
    AssignmentP1,
    LiteralP1,
    LiteralP2,
    LiteralP3,
    Data_TypeP1,
    Data_TypeP2,
    Data_TypeP3,
}
use ProdKind as PK;
impl std::fmt::Debug for ProdKind {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let name = match self {
            ProdKind::ProgramP1 => {
                "Program: TokenId TokenParOpen TokenParClose TokenCBOpen Body TokenCBClose"
            }
            ProdKind::BodyP1 => "Body: TokenInit InitBody Expressions",
            ProdKind::InitBodyP1 => "InitBody: TokenCBOpen VarDeclarations TokenCBClose",
            ProdKind::VarDeclarationsP1 => "VarDeclarations: VarDeclaration",
            ProdKind::VarDeclarationsP2 => {
                "VarDeclarations: VarDeclaration VarDeclarations"
            }
            ProdKind::VarDeclarationP1 => "VarDeclaration: TokenId TokenColon Data_Type",
            ProdKind::ExpressionsP1 => "Expressions: Expression",
            ProdKind::ExpressionsP2 => "Expressions: Expression Expressions",
            ProdKind::ExpressionP1 => "Expression: Assignment",
            ProdKind::AssignmentP1 => "Assignment: TokenId TokenAssign Literal",
            ProdKind::LiteralP1 => "Literal: TokenIntLiteral",
            ProdKind::LiteralP2 => "Literal: TokenFloatLiteral",
            ProdKind::LiteralP3 => "Literal: TokenStringLiteral",
            ProdKind::Data_TypeP1 => "Data_Type: TokenInt",
            ProdKind::Data_TypeP2 => "Data_Type: TokenFloat",
            ProdKind::Data_TypeP3 => "Data_Type: TokenString",
        };
        write!(f, "{name}")
    }
}
#[allow(clippy::upper_case_acronyms)]
#[allow(dead_code)]
#[derive(Clone, Copy, Debug)]
pub enum NonTermKind {
    EMPTY,
    AUG,
    Program,
    Body,
    InitBody,
    VarDeclarations,
    VarDeclaration,
    Expressions,
    Expression,
    Assignment,
    Literal,
    Data_Type,
}
impl From<ProdKind> for NonTermKind {
    fn from(prod: ProdKind) -> Self {
        match prod {
            ProdKind::ProgramP1 => NonTermKind::Program,
            ProdKind::BodyP1 => NonTermKind::Body,
            ProdKind::InitBodyP1 => NonTermKind::InitBody,
            ProdKind::VarDeclarationsP1 => NonTermKind::VarDeclarations,
            ProdKind::VarDeclarationsP2 => NonTermKind::VarDeclarations,
            ProdKind::VarDeclarationP1 => NonTermKind::VarDeclaration,
            ProdKind::ExpressionsP1 => NonTermKind::Expressions,
            ProdKind::ExpressionsP2 => NonTermKind::Expressions,
            ProdKind::ExpressionP1 => NonTermKind::Expression,
            ProdKind::AssignmentP1 => NonTermKind::Assignment,
            ProdKind::LiteralP1 => NonTermKind::Literal,
            ProdKind::LiteralP2 => NonTermKind::Literal,
            ProdKind::LiteralP3 => NonTermKind::Literal,
            ProdKind::Data_TypeP1 => NonTermKind::Data_Type,
            ProdKind::Data_TypeP2 => NonTermKind::Data_Type,
            ProdKind::Data_TypeP3 => NonTermKind::Data_Type,
        }
    }
}
#[allow(clippy::enum_variant_names)]
#[derive(Default, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum State {
    #[default]
    AUGS0,
    TokenIdS1,
    ProgramS2,
    TokenParOpenS3,
    TokenParCloseS4,
    TokenCBOpenS5,
    TokenInitS6,
    BodyS7,
    TokenCBOpenS8,
    InitBodyS9,
    TokenCBCloseS10,
    TokenIdS11,
    VarDeclarationsS12,
    VarDeclarationS13,
    TokenIdS14,
    ExpressionsS15,
    ExpressionS16,
    AssignmentS17,
    TokenColonS18,
    TokenCBCloseS19,
    VarDeclarationsS20,
    TokenAssignS21,
    ExpressionsS22,
    TokenIntS23,
    TokenFloatS24,
    TokenStringS25,
    Data_TypeS26,
    TokenIntLiteralS27,
    TokenFloatLiteralS28,
    TokenStringLiteralS29,
    LiteralS30,
}
impl StateT for State {
    fn default_layout() -> Option<Self> {
        None
    }
}
impl From<State> for usize {
    fn from(s: State) -> Self {
        s as usize
    }
}
impl std::fmt::Debug for State {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let name = match self {
            State::AUGS0 => "0:AUG",
            State::TokenIdS1 => "1:TokenId",
            State::ProgramS2 => "2:Program",
            State::TokenParOpenS3 => "3:TokenParOpen",
            State::TokenParCloseS4 => "4:TokenParClose",
            State::TokenCBOpenS5 => "5:TokenCBOpen",
            State::TokenInitS6 => "6:TokenInit",
            State::BodyS7 => "7:Body",
            State::TokenCBOpenS8 => "8:TokenCBOpen",
            State::InitBodyS9 => "9:InitBody",
            State::TokenCBCloseS10 => "10:TokenCBClose",
            State::TokenIdS11 => "11:TokenId",
            State::VarDeclarationsS12 => "12:VarDeclarations",
            State::VarDeclarationS13 => "13:VarDeclaration",
            State::TokenIdS14 => "14:TokenId",
            State::ExpressionsS15 => "15:Expressions",
            State::ExpressionS16 => "16:Expression",
            State::AssignmentS17 => "17:Assignment",
            State::TokenColonS18 => "18:TokenColon",
            State::TokenCBCloseS19 => "19:TokenCBClose",
            State::VarDeclarationsS20 => "20:VarDeclarations",
            State::TokenAssignS21 => "21:TokenAssign",
            State::ExpressionsS22 => "22:Expressions",
            State::TokenIntS23 => "23:TokenInt",
            State::TokenFloatS24 => "24:TokenFloat",
            State::TokenStringS25 => "25:TokenString",
            State::Data_TypeS26 => "26:Data_Type",
            State::TokenIntLiteralS27 => "27:TokenIntLiteral",
            State::TokenFloatLiteralS28 => "28:TokenFloatLiteral",
            State::TokenStringLiteralS29 => "29:TokenStringLiteral",
            State::LiteralS30 => "30:Literal",
        };
        write!(f, "{name}")
    }
}
#[derive(Debug)]
pub enum Symbol {
    Terminal(Terminal),
    NonTerminal(NonTerminal),
}
#[allow(clippy::upper_case_acronyms)]
#[derive(Debug)]
pub enum Terminal {
    TokenInt(grammar_actions::TokenInt),
    TokenFloat(grammar_actions::TokenFloat),
    TokenString(grammar_actions::TokenString),
    TokenIntLiteral(grammar_actions::TokenIntLiteral),
    TokenFloatLiteral(grammar_actions::TokenFloatLiteral),
    TokenStringLiteral(grammar_actions::TokenStringLiteral),
    TokenId(grammar_actions::TokenId),
    TokenAssign(grammar_actions::TokenAssign),
    TokenParOpen(grammar_actions::TokenParOpen),
    TokenParClose(grammar_actions::TokenParClose),
    TokenCBOpen(grammar_actions::TokenCBOpen),
    TokenCBClose(grammar_actions::TokenCBClose),
    TokenColon(grammar_actions::TokenColon),
    TokenInit(grammar_actions::TokenInit),
}
#[derive(Debug)]
pub enum NonTerminal {
    Program(grammar_actions::Program),
    Body(grammar_actions::Body),
    InitBody(grammar_actions::InitBody),
    VarDeclarations(grammar_actions::VarDeclarations),
    VarDeclaration(grammar_actions::VarDeclaration),
    Expressions(grammar_actions::Expressions),
    Expression(grammar_actions::Expression),
    Assignment(grammar_actions::Assignment),
    Literal(grammar_actions::Literal),
    Data_Type(grammar_actions::Data_Type),
}
type ActionFn = fn(token: TokenKind) -> Vec<Action<State, ProdKind>>;
pub struct GrammarParserDefinition {
    actions: [ActionFn; STATE_COUNT],
    gotos: [fn(nonterm: NonTermKind) -> State; STATE_COUNT],
    token_kinds: [[Option<(TokenKind, bool)>; MAX_RECOGNIZERS]; STATE_COUNT],
}
fn action_aug_s0(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS1)]),
        _ => vec![],
    }
}
fn action_tokenid_s1(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenParOpen => Vec::from(&[Shift(State::TokenParOpenS3)]),
        _ => vec![],
    }
}
fn action_program_s2(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Accept]),
        _ => vec![],
    }
}
fn action_tokenparopen_s3(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenParClose => Vec::from(&[Shift(State::TokenParCloseS4)]),
        _ => vec![],
    }
}
fn action_tokenparclose_s4(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBOpen => Vec::from(&[Shift(State::TokenCBOpenS5)]),
        _ => vec![],
    }
}
fn action_tokencbopen_s5(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenInit => Vec::from(&[Shift(State::TokenInitS6)]),
        _ => vec![],
    }
}
fn action_tokeninit_s6(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBOpen => Vec::from(&[Shift(State::TokenCBOpenS8)]),
        _ => vec![],
    }
}
fn action_body_s7(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Shift(State::TokenCBCloseS10)]),
        _ => vec![],
    }
}
fn action_tokencbopen_s8(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS11)]),
        _ => vec![],
    }
}
fn action_initbody_s9(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS14)]),
        _ => vec![],
    }
}
fn action_tokencbclose_s10(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Reduce(PK::ProgramP1, 6usize)]),
        _ => vec![],
    }
}
fn action_tokenid_s11(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenColon => Vec::from(&[Shift(State::TokenColonS18)]),
        _ => vec![],
    }
}
fn action_vardeclarations_s12(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Shift(State::TokenCBCloseS19)]),
        _ => vec![],
    }
}
fn action_vardeclaration_s13(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS11)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::VarDeclarationsP1, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenid_s14(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenAssign => Vec::from(&[Shift(State::TokenAssignS21)]),
        _ => vec![],
    }
}
fn action_expressions_s15(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Reduce(PK::BodyP1, 3usize)]),
        _ => vec![],
    }
}
fn action_expression_s16(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS14)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::ExpressionsP1, 1usize)]),
        _ => vec![],
    }
}
fn action_assignment_s17(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::ExpressionP1, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::ExpressionP1, 1usize)]),
        _ => vec![],
    }
}
fn action_tokencolon_s18(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenInt => Vec::from(&[Shift(State::TokenIntS23)]),
        TK::TokenFloat => Vec::from(&[Shift(State::TokenFloatS24)]),
        TK::TokenString => Vec::from(&[Shift(State::TokenStringS25)]),
        _ => vec![],
    }
}
fn action_tokencbclose_s19(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::InitBodyP1, 3usize)]),
        _ => vec![],
    }
}
fn action_vardeclarations_s20(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Reduce(PK::VarDeclarationsP2, 2usize)]),
        _ => vec![],
    }
}
fn action_tokenassign_s21(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenIntLiteral => Vec::from(&[Shift(State::TokenIntLiteralS27)]),
        TK::TokenFloatLiteral => Vec::from(&[Shift(State::TokenFloatLiteralS28)]),
        TK::TokenStringLiteral => Vec::from(&[Shift(State::TokenStringLiteralS29)]),
        _ => vec![],
    }
}
fn action_expressions_s22(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Reduce(PK::ExpressionsP2, 2usize)]),
        _ => vec![],
    }
}
fn action_tokenint_s23(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::Data_TypeP1, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::Data_TypeP1, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenfloat_s24(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::Data_TypeP2, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::Data_TypeP2, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenstring_s25(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::Data_TypeP3, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::Data_TypeP3, 1usize)]),
        _ => vec![],
    }
}
fn action_data_type_s26(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::VarDeclarationP1, 3usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::VarDeclarationP1, 3usize)]),
        _ => vec![],
    }
}
fn action_tokenintliteral_s27(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::LiteralP1, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::LiteralP1, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenfloatliteral_s28(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::LiteralP2, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::LiteralP2, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenstringliteral_s29(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::LiteralP3, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::LiteralP3, 1usize)]),
        _ => vec![],
    }
}
fn action_literal_s30(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::AssignmentP1, 3usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::AssignmentP1, 3usize)]),
        _ => vec![],
    }
}
fn goto_aug_s0(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Program => State::ProgramS2,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::AUGS0
            )
        }
    }
}
fn goto_tokencbopen_s5(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Body => State::BodyS7,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenCBOpenS5
            )
        }
    }
}
fn goto_tokeninit_s6(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::InitBody => State::InitBodyS9,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenInitS6
            )
        }
    }
}
fn goto_tokencbopen_s8(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::VarDeclarations => State::VarDeclarationsS12,
        NonTermKind::VarDeclaration => State::VarDeclarationS13,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenCBOpenS8
            )
        }
    }
}
fn goto_initbody_s9(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Expressions => State::ExpressionsS15,
        NonTermKind::Expression => State::ExpressionS16,
        NonTermKind::Assignment => State::AssignmentS17,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::InitBodyS9
            )
        }
    }
}
fn goto_vardeclaration_s13(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::VarDeclarations => State::VarDeclarationsS20,
        NonTermKind::VarDeclaration => State::VarDeclarationS13,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::VarDeclarationS13
            )
        }
    }
}
fn goto_expression_s16(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Expressions => State::ExpressionsS22,
        NonTermKind::Expression => State::ExpressionS16,
        NonTermKind::Assignment => State::AssignmentS17,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::ExpressionS16
            )
        }
    }
}
fn goto_tokencolon_s18(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Data_Type => State::Data_TypeS26,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenColonS18
            )
        }
    }
}
fn goto_tokenassign_s21(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Literal => State::LiteralS30,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenAssignS21
            )
        }
    }
}
fn goto_invalid(_nonterm_kind: NonTermKind) -> State {
    panic!("Invalid GOTO entry!");
}
pub(crate) static PARSER_DEFINITION: GrammarParserDefinition = GrammarParserDefinition {
    actions: [
        action_aug_s0,
        action_tokenid_s1,
        action_program_s2,
        action_tokenparopen_s3,
        action_tokenparclose_s4,
        action_tokencbopen_s5,
        action_tokeninit_s6,
        action_body_s7,
        action_tokencbopen_s8,
        action_initbody_s9,
        action_tokencbclose_s10,
        action_tokenid_s11,
        action_vardeclarations_s12,
        action_vardeclaration_s13,
        action_tokenid_s14,
        action_expressions_s15,
        action_expression_s16,
        action_assignment_s17,
        action_tokencolon_s18,
        action_tokencbclose_s19,
        action_vardeclarations_s20,
        action_tokenassign_s21,
        action_expressions_s22,
        action_tokenint_s23,
        action_tokenfloat_s24,
        action_tokenstring_s25,
        action_data_type_s26,
        action_tokenintliteral_s27,
        action_tokenfloatliteral_s28,
        action_tokenstringliteral_s29,
        action_literal_s30,
    ],
    gotos: [
        goto_aug_s0,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_tokencbopen_s5,
        goto_tokeninit_s6,
        goto_invalid,
        goto_tokencbopen_s8,
        goto_initbody_s9,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_vardeclaration_s13,
        goto_invalid,
        goto_invalid,
        goto_expression_s16,
        goto_invalid,
        goto_tokencolon_s18,
        goto_invalid,
        goto_invalid,
        goto_tokenassign_s21,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
    ],
    token_kinds: [
        [Some((TK::TokenId, false)), None, None],
        [Some((TK::TokenParOpen, false)), None, None],
        [Some((TK::STOP, false)), None, None],
        [Some((TK::TokenParClose, false)), None, None],
        [Some((TK::TokenCBOpen, false)), None, None],
        [Some((TK::TokenInit, false)), None, None],
        [Some((TK::TokenCBOpen, false)), None, None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), None, None],
        [Some((TK::TokenId, false)), None, None],
        [Some((TK::STOP, false)), None, None],
        [Some((TK::TokenColon, false)), None, None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenAssign, false)), None, None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [
            Some((TK::TokenInt, false)),
            Some((TK::TokenFloat, false)),
            Some((TK::TokenString, false)),
        ],
        [Some((TK::TokenId, false)), None, None],
        [Some((TK::TokenCBClose, false)), None, None],
        [
            Some((TK::TokenIntLiteral, false)),
            Some((TK::TokenFloatLiteral, false)),
            Some((TK::TokenStringLiteral, false)),
        ],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
    ],
};
impl ParserDefinition<State, ProdKind, TokenKind, NonTermKind>
for GrammarParserDefinition {
    fn actions(&self, state: State, token: TokenKind) -> Vec<Action<State, ProdKind>> {
        PARSER_DEFINITION.actions[state as usize](token)
    }
    fn goto(&self, state: State, nonterm: NonTermKind) -> State {
        PARSER_DEFINITION.gotos[state as usize](nonterm)
    }
    fn expected_token_kinds(&self, state: State) -> Vec<(TokenKind, bool)> {
        PARSER_DEFINITION.token_kinds[state as usize].iter().map_while(|t| *t).collect()
    }
    fn longest_match() -> bool {
        true
    }
    fn grammar_order() -> bool {
        true
    }
}
pub(crate) type Context<'i, I> = LRContext<'i, I, State, TokenKind>;
pub struct GrammarParser<
    'i,
    I: InputT + ?Sized,
    L: Lexer<'i, Context<'i, I>, State, TokenKind, Input = I>,
    B,
>(
    LRParser<
        'i,
        Context<'i, I>,
        State,
        ProdKind,
        TokenKind,
        NonTermKind,
        GrammarParserDefinition,
        L,
        B,
        I,
    >,
);
#[allow(dead_code)]
impl<'i, L> GrammarParser<'i, Input, L, DefaultBuilder>
where
    L: Lexer<'i, Context<'i, Input>, State, TokenKind, Input = Input>,
{
    pub fn new(lexer: L) -> Self {
        Self(
            LRParser::new(
                &PARSER_DEFINITION,
                State::default(),
                false,
                false,
                lexer,
                DefaultBuilder::new(),
            ),
        )
    }
}
#[allow(dead_code)]
impl<'i, I, L, B> Parser<'i, I, Context<'i, I>, State, TokenKind>
for GrammarParser<'i, I, L, B>
where
    I: InputT + ?Sized + Debug,
    L: Lexer<'i, Context<'i, I>, State, TokenKind, Input = I>,
    B: LRBuilder<'i, I, Context<'i, I>, State, ProdKind, TokenKind>,
{
    type Output = B::Output;
    fn parse(&self, input: &'i I) -> Result<Self::Output> {
        self.0.parse(input)
    }
    fn parse_with_context(
        &self,
        context: &mut Context<'i, I>,
        input: &'i I,
    ) -> Result<Self::Output> {
        self.0.parse_with_context(context, input)
    }
    fn parse_file<'a, F: AsRef<std::path::Path>>(
        &'a mut self,
        file: F,
    ) -> Result<Self::Output>
    where
        'a: 'i,
    {
        self.0.parse_file(file)
    }
}
pub struct DefaultBuilder {
    res_stack: Vec<Symbol>,
}
impl DefaultBuilder {
    #[allow(dead_code)]
    pub fn new() -> Self {
        Self { res_stack: vec![] }
    }
}
impl Builder for DefaultBuilder {
    type Output = grammar_actions::Program;
    fn get_result(&mut self) -> Self::Output {
        match self.res_stack.pop().unwrap() {
            Symbol::NonTerminal(NonTerminal::Program(r)) => r,
            _ => panic!("Invalid result on the parse stack!"),
        }
    }
}
impl<'i> LRBuilder<'i, Input, Context<'i, Input>, State, ProdKind, TokenKind>
for DefaultBuilder {
    #![allow(unused_variables)]
    fn shift_action(
        &mut self,
        context: &Context<'i, Input>,
        token: Token<'i, Input, TokenKind>,
    ) {
        let val = match token.kind {
            TokenKind::STOP => panic!("Cannot shift STOP token!"),
            TokenKind::TokenInt => {
                Terminal::TokenInt(grammar_actions::token_int(context, token))
            }
            TokenKind::TokenFloat => {
                Terminal::TokenFloat(grammar_actions::token_float(context, token))
            }
            TokenKind::TokenString => {
                Terminal::TokenString(grammar_actions::token_string(context, token))
            }
            TokenKind::TokenIntLiteral => {
                Terminal::TokenIntLiteral(
                    grammar_actions::token_int_literal(context, token),
                )
            }
            TokenKind::TokenFloatLiteral => {
                Terminal::TokenFloatLiteral(
                    grammar_actions::token_float_literal(context, token),
                )
            }
            TokenKind::TokenStringLiteral => {
                Terminal::TokenStringLiteral(
                    grammar_actions::token_string_literal(context, token),
                )
            }
            TokenKind::TokenId => {
                Terminal::TokenId(grammar_actions::token_id(context, token))
            }
            TokenKind::TokenAssign => {
                Terminal::TokenAssign(grammar_actions::token_assign(context, token))
            }
            TokenKind::TokenParOpen => {
                Terminal::TokenParOpen(grammar_actions::token_par_open(context, token))
            }
            TokenKind::TokenParClose => {
                Terminal::TokenParClose(grammar_actions::token_par_close(context, token))
            }
            TokenKind::TokenCBOpen => {
                Terminal::TokenCBOpen(grammar_actions::token_cbopen(context, token))
            }
            TokenKind::TokenCBClose => {
                Terminal::TokenCBClose(grammar_actions::token_cbclose(context, token))
            }
            TokenKind::TokenColon => {
                Terminal::TokenColon(grammar_actions::token_colon(context, token))
            }
            TokenKind::TokenInit => {
                Terminal::TokenInit(grammar_actions::token_init(context, token))
            }
            _ => panic!("Shift of unreachable terminal!"),
        };
        self.res_stack.push(Symbol::Terminal(val));
    }
    fn reduce_action(
        &mut self,
        context: &Context<'i, Input>,
        prod: ProdKind,
        prod_len: usize,
    ) {
        let prod = match prod {
            ProdKind::ProgramP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 6usize)
                    .into_iter();
                match (
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                ) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenParOpen(p1)),
                        Symbol::Terminal(Terminal::TokenParClose(p2)),
                        Symbol::Terminal(Terminal::TokenCBOpen(p3)),
                        Symbol::NonTerminal(NonTerminal::Body(p4)),
                        Symbol::Terminal(Terminal::TokenCBClose(p5)),
                    ) => {
                        NonTerminal::Program(
                            grammar_actions::program_c1(context, p0, p1, p2, p3, p4, p5),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::BodyP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenInit(p0)),
                        Symbol::NonTerminal(NonTerminal::InitBody(p1)),
                        Symbol::NonTerminal(NonTerminal::Expressions(p2)),
                    ) => NonTerminal::Body(grammar_actions::body_c1(context, p0, p1, p2)),
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::InitBodyP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenCBOpen(p0)),
                        Symbol::NonTerminal(NonTerminal::VarDeclarations(p1)),
                        Symbol::Terminal(Terminal::TokenCBClose(p2)),
                    ) => {
                        NonTerminal::InitBody(
                            grammar_actions::init_body_c1(context, p0, p1, p2),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationsP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::VarDeclaration(p0)) => {
                        NonTerminal::VarDeclarations(
                            grammar_actions::var_declarations_var_declaration(
                                context,
                                p0,
                            ),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationsP2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 2usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::NonTerminal(NonTerminal::VarDeclaration(p0)),
                        Symbol::NonTerminal(NonTerminal::VarDeclarations(p1)),
                    ) => {
                        NonTerminal::VarDeclarations(
                            grammar_actions::var_declarations_c2(context, p0, p1),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenColon(p1)),
                        Symbol::NonTerminal(NonTerminal::Data_Type(p2)),
                    ) => {
                        NonTerminal::VarDeclaration(
                            grammar_actions::var_declaration_c1(context, p0, p1, p2),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::ExpressionsP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::Expression(p0)) => {
                        NonTerminal::Expressions(
                            grammar_actions::expressions_expression(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::ExpressionsP2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 2usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::NonTerminal(NonTerminal::Expression(p0)),
                        Symbol::NonTerminal(NonTerminal::Expressions(p1)),
                    ) => {
                        NonTerminal::Expressions(
                            grammar_actions::expressions_c2(context, p0, p1),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::ExpressionP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::Assignment(p0)) => {
                        NonTerminal::Expression(
                            grammar_actions::expression_assignment(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::AssignmentP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenAssign(p1)),
                        Symbol::NonTerminal(NonTerminal::Literal(p2)),
                    ) => {
                        NonTerminal::Assignment(
                            grammar_actions::assignment_c1(context, p0, p1, p2),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::LiteralP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenIntLiteral(p0)) => {
                        NonTerminal::Literal(
                            grammar_actions::literal_token_int_literal(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::LiteralP2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenFloatLiteral(p0)) => {
                        NonTerminal::Literal(
                            grammar_actions::literal_token_float_literal(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::LiteralP3 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenStringLiteral(p0)) => {
                        NonTerminal::Literal(
                            grammar_actions::literal_token_string_literal(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Data_TypeP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenInt(p0)) => {
                        NonTerminal::Data_Type(
                            grammar_actions::data_type_token_int(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Data_TypeP2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenFloat(p0)) => {
                        NonTerminal::Data_Type(
                            grammar_actions::data_type_token_float(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Data_TypeP3 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenString(p0)) => {
                        NonTerminal::Data_Type(
                            grammar_actions::data_type_token_string(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
        };
        self.res_stack.push(Symbol::NonTerminal(prod));
    }
}
