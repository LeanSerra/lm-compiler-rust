/// Generated by rustemo. Do not edit manually!
use std::fmt::Debug;
use std::hash::Hash;
use rustemo::{
    Result, Input as InputT, Lexer, Token, TokenRecognizer as TokenRecognizerT, Parser,
    ParserDefinition, State as StateT, Builder,
};
use rustemo::LRBuilder;
use super::grammar_actions;
use rustemo::{LRParser, LRContext};
use rustemo::Action::{self, Shift, Reduce, Accept};
#[allow(unused_imports)]
use rustemo::debug::{log, logn};
#[allow(unused_imports)]
#[cfg(debug_assertions)]
use rustemo::colored::*;
pub type Input = str;
const STATE_COUNT: usize = 34usize;
const MAX_RECOGNIZERS: usize = 3usize;
#[allow(dead_code)]
const TERMINAL_COUNT: usize = 35usize;
#[allow(clippy::upper_case_acronyms)]
#[derive(Debug, Default, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub enum TokenKind {
    #[default]
    STOP,
    TokenInt,
    TokenFloat,
    TokenString,
    TokenIntLiteral,
    TokenFloatLiteral,
    TokenStringLiteral,
    TokenId,
    TokenAssign,
    TokenSum,
    TokenMul,
    TokenSub,
    TokenDiv,
    TokenParOpen,
    TokenParClose,
    TokenCBOpen,
    TokenCBClose,
    TokenSemicolon,
    TokenColon,
    TokenInit,
    TokenWhile,
    TokenEqual,
    TokenNotEqual,
    TokenLess,
    TokenLessEqual,
    TokenGreater,
    TokenGreaterEqual,
    TokenTrue,
    TokenFalse,
    TokenIf,
    TokenElse,
    TokenComma,
    TokenAnd,
    TokenOr,
    TokenNot,
}
use TokenKind as TK;
impl From<TokenKind> for usize {
    fn from(t: TokenKind) -> Self {
        t as usize
    }
}
#[allow(clippy::enum_variant_names)]
#[derive(Clone, Copy, PartialEq)]
pub enum ProdKind {
    ProgramProgram,
    BodyBodyInitExpressions,
    BodyBodyInit,
    BodyBodyExpressions,
    BodyBodyEmpty,
    InitBodyInitBody,
    VarDeclarationsVarDeclarationsSingle,
    VarDeclarationsVarDeclarationsRecursive,
    VarDeclarationVarDeclarationSingle,
    VarDeclarationVarDeclarationRecursive,
    ExpressionsExpressionSingle,
    ExpressionsExpressionRecursive,
    ExpressionExpressionAssignment,
    AssignmentAssignment,
    LiteralIntegerLiteral,
    LiteralFloatLiteral,
    LiteralStringLiteral,
    Data_TypeIntType,
    Data_TypeFloatType,
    Data_TypeStringType,
    WhileLoopWhile,
    ConditionConditionSingle,
    ConditionConditionTrue,
    ConditionConditionFalse,
    ConditionConditionRecursive,
    ConjunctionConjunctionAnd,
    ConjunctionConjunctionOr,
    ComparisonOpComparisonOpEqual,
    ComparisonOpComparisonOpNotEqual,
    ComparisonOpComparisonOpLess,
    ComparisonOpComparisonOpLessEqual,
    ComparisonOpComparisonOpGreater,
    ComparisonOpComparisonOpGreaterEqual,
    IfIf,
    ElseElse,
    ArithmeticOperationArithmeticOperationIdId,
    ArithmeticOperationArithmeticOperationIdNumber,
    ArithmeticOperationArithmeticOperationNumberId,
    ArithmeticOperationArithmeticOperationNumberNumber,
    NumberNumberInt,
    NumberNumberFloat,
    ArithmeticOperatorArithmeticOperatorSum,
    ArithmeticOperatorArithmeticOperatorMul,
    ArithmeticOperatorArithmeticOperatorSub,
    ArithmeticOperatorArithmeticOperatorDiv,
    NotNot,
}
use ProdKind as PK;
impl std::fmt::Debug for ProdKind {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let name = match self {
            ProdKind::ProgramProgram => {
                "Program: TokenId TokenParOpen TokenParClose TokenCBOpen Body TokenCBClose"
            }
            ProdKind::BodyBodyInitExpressions => "Body: TokenInit InitBody Expressions",
            ProdKind::BodyBodyInit => "Body: TokenInit InitBody",
            ProdKind::BodyBodyExpressions => "Body: Expressions",
            ProdKind::BodyBodyEmpty => "Body: ",
            ProdKind::InitBodyInitBody => {
                "InitBody: TokenCBOpen VarDeclarations TokenCBClose"
            }
            ProdKind::VarDeclarationsVarDeclarationsSingle => {
                "VarDeclarations: VarDeclaration"
            }
            ProdKind::VarDeclarationsVarDeclarationsRecursive => {
                "VarDeclarations: VarDeclaration VarDeclarations"
            }
            ProdKind::VarDeclarationVarDeclarationSingle => {
                "VarDeclaration: TokenId TokenColon Data_Type"
            }
            ProdKind::VarDeclarationVarDeclarationRecursive => {
                "VarDeclaration: TokenId TokenComma VarDeclaration"
            }
            ProdKind::ExpressionsExpressionSingle => "Expressions: Expression",
            ProdKind::ExpressionsExpressionRecursive => {
                "Expressions: Expression Expressions"
            }
            ProdKind::ExpressionExpressionAssignment => "Expression: Assignment",
            ProdKind::AssignmentAssignment => "Assignment: TokenId TokenAssign Literal",
            ProdKind::LiteralIntegerLiteral => "Literal: TokenIntLiteral",
            ProdKind::LiteralFloatLiteral => "Literal: TokenFloatLiteral",
            ProdKind::LiteralStringLiteral => "Literal: TokenStringLiteral",
            ProdKind::Data_TypeIntType => "Data_Type: TokenInt",
            ProdKind::Data_TypeFloatType => "Data_Type: TokenFloat",
            ProdKind::Data_TypeStringType => "Data_Type: TokenString",
            ProdKind::WhileLoopWhile => {
                "WhileLoop: TokenWhile TokenParOpen Condition TokenParClose TokenCBOpen Body TokenCBClose"
            }
            ProdKind::ConditionConditionSingle => {
                "Condition: Expression ComparisonOp Expression"
            }
            ProdKind::ConditionConditionTrue => "Condition: TokenTrue",
            ProdKind::ConditionConditionFalse => "Condition: TokenFalse",
            ProdKind::ConditionConditionRecursive => {
                "Condition: Expression ComparisonOp Expression Conjunction Condition"
            }
            ProdKind::ConjunctionConjunctionAnd => "Conjunction: TokenAnd",
            ProdKind::ConjunctionConjunctionOr => "Conjunction: TokenOr",
            ProdKind::ComparisonOpComparisonOpEqual => "ComparisonOp: TokenEqual",
            ProdKind::ComparisonOpComparisonOpNotEqual => "ComparisonOp: TokenNotEqual",
            ProdKind::ComparisonOpComparisonOpLess => "ComparisonOp: TokenLess",
            ProdKind::ComparisonOpComparisonOpLessEqual => "ComparisonOp: TokenLessEqual",
            ProdKind::ComparisonOpComparisonOpGreater => "ComparisonOp: TokenGreater",
            ProdKind::ComparisonOpComparisonOpGreaterEqual => {
                "ComparisonOp: TokenGreaterEqual"
            }
            ProdKind::IfIf => {
                "If: TokenIf TokenParOpen Condition TokenParClose TokenCBOpen Body TokenCBClose"
            }
            ProdKind::ElseElse => "Else: TokenElse TokenCBOpen Body TokenCBClose",
            ProdKind::ArithmeticOperationArithmeticOperationIdId => {
                "ArithmeticOperation: TokenId ArithmeticOperator TokenId"
            }
            ProdKind::ArithmeticOperationArithmeticOperationIdNumber => {
                "ArithmeticOperation: TokenId ArithmeticOperator Number"
            }
            ProdKind::ArithmeticOperationArithmeticOperationNumberId => {
                "ArithmeticOperation: Number ArithmeticOperator TokenId"
            }
            ProdKind::ArithmeticOperationArithmeticOperationNumberNumber => {
                "ArithmeticOperation: Number ArithmeticOperator Number"
            }
            ProdKind::NumberNumberInt => "Number: TokenIntLiteral",
            ProdKind::NumberNumberFloat => "Number: TokenFloatLiteral",
            ProdKind::ArithmeticOperatorArithmeticOperatorSum => {
                "ArithmeticOperator: TokenSum"
            }
            ProdKind::ArithmeticOperatorArithmeticOperatorMul => {
                "ArithmeticOperator: TokenMul"
            }
            ProdKind::ArithmeticOperatorArithmeticOperatorSub => {
                "ArithmeticOperator: TokenSub"
            }
            ProdKind::ArithmeticOperatorArithmeticOperatorDiv => {
                "ArithmeticOperator: TokenDiv"
            }
            ProdKind::NotNot => "Not: TokenNot Condition",
        };
        write!(f, "{name}")
    }
}
#[allow(clippy::upper_case_acronyms)]
#[allow(dead_code)]
#[derive(Clone, Copy, Debug)]
pub enum NonTermKind {
    EMPTY,
    AUG,
    Program,
    Body,
    InitBody,
    VarDeclarations,
    VarDeclaration,
    Expressions,
    Expression,
    Assignment,
    Literal,
    Data_Type,
    WhileLoop,
    Condition,
    Conjunction,
    ComparisonOp,
    If,
    Else,
    ArithmeticOperation,
    Number,
    ArithmeticOperator,
    Not,
}
impl From<ProdKind> for NonTermKind {
    fn from(prod: ProdKind) -> Self {
        match prod {
            ProdKind::ProgramProgram => NonTermKind::Program,
            ProdKind::BodyBodyInitExpressions => NonTermKind::Body,
            ProdKind::BodyBodyInit => NonTermKind::Body,
            ProdKind::BodyBodyExpressions => NonTermKind::Body,
            ProdKind::BodyBodyEmpty => NonTermKind::Body,
            ProdKind::InitBodyInitBody => NonTermKind::InitBody,
            ProdKind::VarDeclarationsVarDeclarationsSingle => {
                NonTermKind::VarDeclarations
            }
            ProdKind::VarDeclarationsVarDeclarationsRecursive => {
                NonTermKind::VarDeclarations
            }
            ProdKind::VarDeclarationVarDeclarationSingle => NonTermKind::VarDeclaration,
            ProdKind::VarDeclarationVarDeclarationRecursive => {
                NonTermKind::VarDeclaration
            }
            ProdKind::ExpressionsExpressionSingle => NonTermKind::Expressions,
            ProdKind::ExpressionsExpressionRecursive => NonTermKind::Expressions,
            ProdKind::ExpressionExpressionAssignment => NonTermKind::Expression,
            ProdKind::AssignmentAssignment => NonTermKind::Assignment,
            ProdKind::LiteralIntegerLiteral => NonTermKind::Literal,
            ProdKind::LiteralFloatLiteral => NonTermKind::Literal,
            ProdKind::LiteralStringLiteral => NonTermKind::Literal,
            ProdKind::Data_TypeIntType => NonTermKind::Data_Type,
            ProdKind::Data_TypeFloatType => NonTermKind::Data_Type,
            ProdKind::Data_TypeStringType => NonTermKind::Data_Type,
            ProdKind::WhileLoopWhile => NonTermKind::WhileLoop,
            ProdKind::ConditionConditionSingle => NonTermKind::Condition,
            ProdKind::ConditionConditionTrue => NonTermKind::Condition,
            ProdKind::ConditionConditionFalse => NonTermKind::Condition,
            ProdKind::ConditionConditionRecursive => NonTermKind::Condition,
            ProdKind::ConjunctionConjunctionAnd => NonTermKind::Conjunction,
            ProdKind::ConjunctionConjunctionOr => NonTermKind::Conjunction,
            ProdKind::ComparisonOpComparisonOpEqual => NonTermKind::ComparisonOp,
            ProdKind::ComparisonOpComparisonOpNotEqual => NonTermKind::ComparisonOp,
            ProdKind::ComparisonOpComparisonOpLess => NonTermKind::ComparisonOp,
            ProdKind::ComparisonOpComparisonOpLessEqual => NonTermKind::ComparisonOp,
            ProdKind::ComparisonOpComparisonOpGreater => NonTermKind::ComparisonOp,
            ProdKind::ComparisonOpComparisonOpGreaterEqual => NonTermKind::ComparisonOp,
            ProdKind::IfIf => NonTermKind::If,
            ProdKind::ElseElse => NonTermKind::Else,
            ProdKind::ArithmeticOperationArithmeticOperationIdId => {
                NonTermKind::ArithmeticOperation
            }
            ProdKind::ArithmeticOperationArithmeticOperationIdNumber => {
                NonTermKind::ArithmeticOperation
            }
            ProdKind::ArithmeticOperationArithmeticOperationNumberId => {
                NonTermKind::ArithmeticOperation
            }
            ProdKind::ArithmeticOperationArithmeticOperationNumberNumber => {
                NonTermKind::ArithmeticOperation
            }
            ProdKind::NumberNumberInt => NonTermKind::Number,
            ProdKind::NumberNumberFloat => NonTermKind::Number,
            ProdKind::ArithmeticOperatorArithmeticOperatorSum => {
                NonTermKind::ArithmeticOperator
            }
            ProdKind::ArithmeticOperatorArithmeticOperatorMul => {
                NonTermKind::ArithmeticOperator
            }
            ProdKind::ArithmeticOperatorArithmeticOperatorSub => {
                NonTermKind::ArithmeticOperator
            }
            ProdKind::ArithmeticOperatorArithmeticOperatorDiv => {
                NonTermKind::ArithmeticOperator
            }
            ProdKind::NotNot => NonTermKind::Not,
        }
    }
}
#[allow(clippy::enum_variant_names)]
#[derive(Default, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum State {
    #[default]
    AUGS0,
    TokenIdS1,
    ProgramS2,
    TokenParOpenS3,
    TokenParCloseS4,
    TokenCBOpenS5,
    TokenIdS6,
    TokenInitS7,
    BodyS8,
    ExpressionsS9,
    ExpressionS10,
    AssignmentS11,
    TokenAssignS12,
    TokenCBOpenS13,
    InitBodyS14,
    TokenCBCloseS15,
    ExpressionsS16,
    TokenIntLiteralS17,
    TokenFloatLiteralS18,
    TokenStringLiteralS19,
    LiteralS20,
    TokenIdS21,
    VarDeclarationsS22,
    VarDeclarationS23,
    ExpressionsS24,
    TokenColonS25,
    TokenCommaS26,
    TokenCBCloseS27,
    VarDeclarationsS28,
    TokenIntS29,
    TokenFloatS30,
    TokenStringS31,
    Data_TypeS32,
    VarDeclarationS33,
}
impl StateT for State {
    fn default_layout() -> Option<Self> {
        None
    }
}
impl From<State> for usize {
    fn from(s: State) -> Self {
        s as usize
    }
}
impl std::fmt::Debug for State {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let name = match self {
            State::AUGS0 => "0:AUG",
            State::TokenIdS1 => "1:TokenId",
            State::ProgramS2 => "2:Program",
            State::TokenParOpenS3 => "3:TokenParOpen",
            State::TokenParCloseS4 => "4:TokenParClose",
            State::TokenCBOpenS5 => "5:TokenCBOpen",
            State::TokenIdS6 => "6:TokenId",
            State::TokenInitS7 => "7:TokenInit",
            State::BodyS8 => "8:Body",
            State::ExpressionsS9 => "9:Expressions",
            State::ExpressionS10 => "10:Expression",
            State::AssignmentS11 => "11:Assignment",
            State::TokenAssignS12 => "12:TokenAssign",
            State::TokenCBOpenS13 => "13:TokenCBOpen",
            State::InitBodyS14 => "14:InitBody",
            State::TokenCBCloseS15 => "15:TokenCBClose",
            State::ExpressionsS16 => "16:Expressions",
            State::TokenIntLiteralS17 => "17:TokenIntLiteral",
            State::TokenFloatLiteralS18 => "18:TokenFloatLiteral",
            State::TokenStringLiteralS19 => "19:TokenStringLiteral",
            State::LiteralS20 => "20:Literal",
            State::TokenIdS21 => "21:TokenId",
            State::VarDeclarationsS22 => "22:VarDeclarations",
            State::VarDeclarationS23 => "23:VarDeclaration",
            State::ExpressionsS24 => "24:Expressions",
            State::TokenColonS25 => "25:TokenColon",
            State::TokenCommaS26 => "26:TokenComma",
            State::TokenCBCloseS27 => "27:TokenCBClose",
            State::VarDeclarationsS28 => "28:VarDeclarations",
            State::TokenIntS29 => "29:TokenInt",
            State::TokenFloatS30 => "30:TokenFloat",
            State::TokenStringS31 => "31:TokenString",
            State::Data_TypeS32 => "32:Data_Type",
            State::VarDeclarationS33 => "33:VarDeclaration",
        };
        write!(f, "{name}")
    }
}
#[derive(Debug)]
pub enum Symbol {
    Terminal(Terminal),
    NonTerminal(NonTerminal),
}
#[allow(clippy::upper_case_acronyms)]
#[derive(Debug)]
pub enum Terminal {
    TokenInt(grammar_actions::TokenInt),
    TokenFloat(grammar_actions::TokenFloat),
    TokenString(grammar_actions::TokenString),
    TokenIntLiteral(grammar_actions::TokenIntLiteral),
    TokenFloatLiteral(grammar_actions::TokenFloatLiteral),
    TokenStringLiteral(grammar_actions::TokenStringLiteral),
    TokenId(grammar_actions::TokenId),
    TokenAssign(grammar_actions::TokenAssign),
    TokenParOpen(grammar_actions::TokenParOpen),
    TokenParClose(grammar_actions::TokenParClose),
    TokenCBOpen(grammar_actions::TokenCBOpen),
    TokenCBClose(grammar_actions::TokenCBClose),
    TokenColon(grammar_actions::TokenColon),
    TokenInit(grammar_actions::TokenInit),
    TokenComma(grammar_actions::TokenComma),
}
#[derive(Debug)]
pub enum NonTerminal {
    Program(grammar_actions::Program),
    Body(grammar_actions::Body),
    InitBody(grammar_actions::InitBody),
    VarDeclarations(grammar_actions::VarDeclarations),
    VarDeclaration(grammar_actions::VarDeclaration),
    Expressions(grammar_actions::Expressions),
    Expression(grammar_actions::Expression),
    Assignment(grammar_actions::Assignment),
    Literal(grammar_actions::Literal),
    Data_Type(grammar_actions::Data_Type),
}
type ActionFn = fn(token: TokenKind) -> Vec<Action<State, ProdKind>>;
pub struct GrammarParserDefinition {
    actions: [ActionFn; STATE_COUNT],
    gotos: [fn(nonterm: NonTermKind) -> State; STATE_COUNT],
    token_kinds: [[Option<(TokenKind, bool)>; MAX_RECOGNIZERS]; STATE_COUNT],
}
fn action_aug_s0(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS1)]),
        _ => vec![],
    }
}
fn action_tokenid_s1(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenParOpen => Vec::from(&[Shift(State::TokenParOpenS3)]),
        _ => vec![],
    }
}
fn action_program_s2(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Accept]),
        _ => vec![],
    }
}
fn action_tokenparopen_s3(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenParClose => Vec::from(&[Shift(State::TokenParCloseS4)]),
        _ => vec![],
    }
}
fn action_tokenparclose_s4(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBOpen => Vec::from(&[Shift(State::TokenCBOpenS5)]),
        _ => vec![],
    }
}
fn action_tokencbopen_s5(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS6)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::BodyBodyEmpty, 0usize)]),
        TK::TokenInit => Vec::from(&[Shift(State::TokenInitS7)]),
        _ => vec![],
    }
}
fn action_tokenid_s6(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenAssign => Vec::from(&[Shift(State::TokenAssignS12)]),
        _ => vec![],
    }
}
fn action_tokeninit_s7(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBOpen => Vec::from(&[Shift(State::TokenCBOpenS13)]),
        _ => vec![],
    }
}
fn action_body_s8(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Shift(State::TokenCBCloseS15)]),
        _ => vec![],
    }
}
fn action_expressions_s9(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Reduce(PK::BodyBodyExpressions, 1usize)]),
        _ => vec![],
    }
}
fn action_expression_s10(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS6)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::ExpressionsExpressionSingle, 1usize)]),
        _ => vec![],
    }
}
fn action_assignment_s11(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::ExpressionExpressionAssignment, 1usize)]),
        TK::TokenCBClose => {
            Vec::from(&[Reduce(PK::ExpressionExpressionAssignment, 1usize)])
        }
        _ => vec![],
    }
}
fn action_tokenassign_s12(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenIntLiteral => Vec::from(&[Shift(State::TokenIntLiteralS17)]),
        TK::TokenFloatLiteral => Vec::from(&[Shift(State::TokenFloatLiteralS18)]),
        TK::TokenStringLiteral => Vec::from(&[Shift(State::TokenStringLiteralS19)]),
        _ => vec![],
    }
}
fn action_tokencbopen_s13(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS21)]),
        _ => vec![],
    }
}
fn action_initbody_s14(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS6)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::BodyBodyInit, 2usize)]),
        _ => vec![],
    }
}
fn action_tokencbclose_s15(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Reduce(PK::ProgramProgram, 6usize)]),
        _ => vec![],
    }
}
fn action_expressions_s16(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => {
            Vec::from(&[Reduce(PK::ExpressionsExpressionRecursive, 2usize)])
        }
        _ => vec![],
    }
}
fn action_tokenintliteral_s17(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::LiteralIntegerLiteral, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::LiteralIntegerLiteral, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenfloatliteral_s18(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::LiteralFloatLiteral, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::LiteralFloatLiteral, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenstringliteral_s19(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::LiteralStringLiteral, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::LiteralStringLiteral, 1usize)]),
        _ => vec![],
    }
}
fn action_literal_s20(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::AssignmentAssignment, 3usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::AssignmentAssignment, 3usize)]),
        _ => vec![],
    }
}
fn action_tokenid_s21(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenColon => Vec::from(&[Shift(State::TokenColonS25)]),
        TK::TokenComma => Vec::from(&[Shift(State::TokenCommaS26)]),
        _ => vec![],
    }
}
fn action_vardeclarations_s22(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Shift(State::TokenCBCloseS27)]),
        _ => vec![],
    }
}
fn action_vardeclaration_s23(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS21)]),
        TK::TokenCBClose => {
            Vec::from(&[Reduce(PK::VarDeclarationsVarDeclarationsSingle, 1usize)])
        }
        _ => vec![],
    }
}
fn action_expressions_s24(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => Vec::from(&[Reduce(PK::BodyBodyInitExpressions, 3usize)]),
        _ => vec![],
    }
}
fn action_tokencolon_s25(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenInt => Vec::from(&[Shift(State::TokenIntS29)]),
        TK::TokenFloat => Vec::from(&[Shift(State::TokenFloatS30)]),
        TK::TokenString => Vec::from(&[Shift(State::TokenStringS31)]),
        _ => vec![],
    }
}
fn action_tokencomma_s26(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Shift(State::TokenIdS21)]),
        _ => vec![],
    }
}
fn action_tokencbclose_s27(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::InitBodyInitBody, 3usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::InitBodyInitBody, 3usize)]),
        _ => vec![],
    }
}
fn action_vardeclarations_s28(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenCBClose => {
            Vec::from(&[Reduce(PK::VarDeclarationsVarDeclarationsRecursive, 2usize)])
        }
        _ => vec![],
    }
}
fn action_tokenint_s29(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::Data_TypeIntType, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::Data_TypeIntType, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenfloat_s30(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::Data_TypeFloatType, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::Data_TypeFloatType, 1usize)]),
        _ => vec![],
    }
}
fn action_tokenstring_s31(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => Vec::from(&[Reduce(PK::Data_TypeStringType, 1usize)]),
        TK::TokenCBClose => Vec::from(&[Reduce(PK::Data_TypeStringType, 1usize)]),
        _ => vec![],
    }
}
fn action_data_type_s32(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => {
            Vec::from(&[Reduce(PK::VarDeclarationVarDeclarationSingle, 3usize)])
        }
        TK::TokenCBClose => {
            Vec::from(&[Reduce(PK::VarDeclarationVarDeclarationSingle, 3usize)])
        }
        _ => vec![],
    }
}
fn action_vardeclaration_s33(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::TokenId => {
            Vec::from(&[Reduce(PK::VarDeclarationVarDeclarationRecursive, 3usize)])
        }
        TK::TokenCBClose => {
            Vec::from(&[Reduce(PK::VarDeclarationVarDeclarationRecursive, 3usize)])
        }
        _ => vec![],
    }
}
fn goto_aug_s0(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Program => State::ProgramS2,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::AUGS0
            )
        }
    }
}
fn goto_tokencbopen_s5(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Body => State::BodyS8,
        NonTermKind::Expressions => State::ExpressionsS9,
        NonTermKind::Expression => State::ExpressionS10,
        NonTermKind::Assignment => State::AssignmentS11,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenCBOpenS5
            )
        }
    }
}
fn goto_tokeninit_s7(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::InitBody => State::InitBodyS14,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenInitS7
            )
        }
    }
}
fn goto_expression_s10(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Expressions => State::ExpressionsS16,
        NonTermKind::Expression => State::ExpressionS10,
        NonTermKind::Assignment => State::AssignmentS11,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::ExpressionS10
            )
        }
    }
}
fn goto_tokenassign_s12(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Literal => State::LiteralS20,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenAssignS12
            )
        }
    }
}
fn goto_tokencbopen_s13(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::VarDeclarations => State::VarDeclarationsS22,
        NonTermKind::VarDeclaration => State::VarDeclarationS23,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenCBOpenS13
            )
        }
    }
}
fn goto_initbody_s14(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Expressions => State::ExpressionsS24,
        NonTermKind::Expression => State::ExpressionS10,
        NonTermKind::Assignment => State::AssignmentS11,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::InitBodyS14
            )
        }
    }
}
fn goto_vardeclaration_s23(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::VarDeclarations => State::VarDeclarationsS28,
        NonTermKind::VarDeclaration => State::VarDeclarationS23,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::VarDeclarationS23
            )
        }
    }
}
fn goto_tokencolon_s25(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Data_Type => State::Data_TypeS32,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenColonS25
            )
        }
    }
}
fn goto_tokencomma_s26(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::VarDeclaration => State::VarDeclarationS33,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::TokenCommaS26
            )
        }
    }
}
fn goto_invalid(_nonterm_kind: NonTermKind) -> State {
    panic!("Invalid GOTO entry!");
}
pub(crate) static PARSER_DEFINITION: GrammarParserDefinition = GrammarParserDefinition {
    actions: [
        action_aug_s0,
        action_tokenid_s1,
        action_program_s2,
        action_tokenparopen_s3,
        action_tokenparclose_s4,
        action_tokencbopen_s5,
        action_tokenid_s6,
        action_tokeninit_s7,
        action_body_s8,
        action_expressions_s9,
        action_expression_s10,
        action_assignment_s11,
        action_tokenassign_s12,
        action_tokencbopen_s13,
        action_initbody_s14,
        action_tokencbclose_s15,
        action_expressions_s16,
        action_tokenintliteral_s17,
        action_tokenfloatliteral_s18,
        action_tokenstringliteral_s19,
        action_literal_s20,
        action_tokenid_s21,
        action_vardeclarations_s22,
        action_vardeclaration_s23,
        action_expressions_s24,
        action_tokencolon_s25,
        action_tokencomma_s26,
        action_tokencbclose_s27,
        action_vardeclarations_s28,
        action_tokenint_s29,
        action_tokenfloat_s30,
        action_tokenstring_s31,
        action_data_type_s32,
        action_vardeclaration_s33,
    ],
    gotos: [
        goto_aug_s0,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_tokencbopen_s5,
        goto_invalid,
        goto_tokeninit_s7,
        goto_invalid,
        goto_invalid,
        goto_expression_s10,
        goto_invalid,
        goto_tokenassign_s12,
        goto_tokencbopen_s13,
        goto_initbody_s14,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_vardeclaration_s23,
        goto_invalid,
        goto_tokencolon_s25,
        goto_tokencomma_s26,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
    ],
    token_kinds: [
        [Some((TK::TokenId, false)), None, None],
        [Some((TK::TokenParOpen, false)), None, None],
        [Some((TK::STOP, false)), None, None],
        [Some((TK::TokenParClose, false)), None, None],
        [Some((TK::TokenCBOpen, false)), None, None],
        [
            Some((TK::TokenId, false)),
            Some((TK::TokenCBClose, false)),
            Some((TK::TokenInit, false)),
        ],
        [Some((TK::TokenAssign, false)), None, None],
        [Some((TK::TokenCBOpen, false)), None, None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [
            Some((TK::TokenIntLiteral, false)),
            Some((TK::TokenFloatLiteral, false)),
            Some((TK::TokenStringLiteral, false)),
        ],
        [Some((TK::TokenId, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::STOP, false)), None, None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenColon, false)), Some((TK::TokenComma, false)), None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenCBClose, false)), None, None],
        [
            Some((TK::TokenInt, false)),
            Some((TK::TokenFloat, false)),
            Some((TK::TokenString, false)),
        ],
        [Some((TK::TokenId, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenCBClose, false)), None, None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
        [Some((TK::TokenId, false)), Some((TK::TokenCBClose, false)), None],
    ],
};
impl ParserDefinition<State, ProdKind, TokenKind, NonTermKind>
for GrammarParserDefinition {
    fn actions(&self, state: State, token: TokenKind) -> Vec<Action<State, ProdKind>> {
        PARSER_DEFINITION.actions[state as usize](token)
    }
    fn goto(&self, state: State, nonterm: NonTermKind) -> State {
        PARSER_DEFINITION.gotos[state as usize](nonterm)
    }
    fn expected_token_kinds(&self, state: State) -> Vec<(TokenKind, bool)> {
        PARSER_DEFINITION.token_kinds[state as usize].iter().map_while(|t| *t).collect()
    }
    fn longest_match() -> bool {
        true
    }
    fn grammar_order() -> bool {
        true
    }
}
pub(crate) type Context<'i, I> = LRContext<'i, I, State, TokenKind>;
pub struct GrammarParser<
    'i,
    I: InputT + ?Sized,
    L: Lexer<'i, Context<'i, I>, State, TokenKind, Input = I>,
    B,
>(
    LRParser<
        'i,
        Context<'i, I>,
        State,
        ProdKind,
        TokenKind,
        NonTermKind,
        GrammarParserDefinition,
        L,
        B,
        I,
    >,
);
#[allow(dead_code)]
impl<'i, L> GrammarParser<'i, Input, L, DefaultBuilder>
where
    L: Lexer<'i, Context<'i, Input>, State, TokenKind, Input = Input>,
{
    pub fn new(lexer: L) -> Self {
        Self(
            LRParser::new(
                &PARSER_DEFINITION,
                State::default(),
                false,
                false,
                lexer,
                DefaultBuilder::new(),
            ),
        )
    }
}
#[allow(dead_code)]
impl<'i, I, L, B> Parser<'i, I, Context<'i, I>, State, TokenKind>
for GrammarParser<'i, I, L, B>
where
    I: InputT + ?Sized + Debug,
    L: Lexer<'i, Context<'i, I>, State, TokenKind, Input = I>,
    B: LRBuilder<'i, I, Context<'i, I>, State, ProdKind, TokenKind>,
{
    type Output = B::Output;
    fn parse(&self, input: &'i I) -> Result<Self::Output> {
        self.0.parse(input)
    }
    fn parse_with_context(
        &self,
        context: &mut Context<'i, I>,
        input: &'i I,
    ) -> Result<Self::Output> {
        self.0.parse_with_context(context, input)
    }
    fn parse_file<'a, F: AsRef<std::path::Path>>(
        &'a mut self,
        file: F,
    ) -> Result<Self::Output>
    where
        'a: 'i,
    {
        self.0.parse_file(file)
    }
}
pub struct DefaultBuilder {
    res_stack: Vec<Symbol>,
}
impl DefaultBuilder {
    #[allow(dead_code)]
    pub fn new() -> Self {
        Self { res_stack: vec![] }
    }
}
impl Builder for DefaultBuilder {
    type Output = grammar_actions::Program;
    fn get_result(&mut self) -> Self::Output {
        match self.res_stack.pop().unwrap() {
            Symbol::NonTerminal(NonTerminal::Program(r)) => r,
            _ => panic!("Invalid result on the parse stack!"),
        }
    }
}
impl<'i> LRBuilder<'i, Input, Context<'i, Input>, State, ProdKind, TokenKind>
for DefaultBuilder {
    #![allow(unused_variables)]
    fn shift_action(
        &mut self,
        context: &Context<'i, Input>,
        token: Token<'i, Input, TokenKind>,
    ) {
        let val = match token.kind {
            TokenKind::STOP => panic!("Cannot shift STOP token!"),
            TokenKind::TokenInt => {
                Terminal::TokenInt(grammar_actions::token_int(context, token))
            }
            TokenKind::TokenFloat => {
                Terminal::TokenFloat(grammar_actions::token_float(context, token))
            }
            TokenKind::TokenString => {
                Terminal::TokenString(grammar_actions::token_string(context, token))
            }
            TokenKind::TokenIntLiteral => {
                Terminal::TokenIntLiteral(
                    grammar_actions::token_int_literal(context, token),
                )
            }
            TokenKind::TokenFloatLiteral => {
                Terminal::TokenFloatLiteral(
                    grammar_actions::token_float_literal(context, token),
                )
            }
            TokenKind::TokenStringLiteral => {
                Terminal::TokenStringLiteral(
                    grammar_actions::token_string_literal(context, token),
                )
            }
            TokenKind::TokenId => {
                Terminal::TokenId(grammar_actions::token_id(context, token))
            }
            TokenKind::TokenAssign => {
                Terminal::TokenAssign(grammar_actions::token_assign(context, token))
            }
            TokenKind::TokenParOpen => {
                Terminal::TokenParOpen(grammar_actions::token_par_open(context, token))
            }
            TokenKind::TokenParClose => {
                Terminal::TokenParClose(grammar_actions::token_par_close(context, token))
            }
            TokenKind::TokenCBOpen => {
                Terminal::TokenCBOpen(grammar_actions::token_cbopen(context, token))
            }
            TokenKind::TokenCBClose => {
                Terminal::TokenCBClose(grammar_actions::token_cbclose(context, token))
            }
            TokenKind::TokenColon => {
                Terminal::TokenColon(grammar_actions::token_colon(context, token))
            }
            TokenKind::TokenInit => {
                Terminal::TokenInit(grammar_actions::token_init(context, token))
            }
            TokenKind::TokenComma => {
                Terminal::TokenComma(grammar_actions::token_comma(context, token))
            }
            _ => panic!("Shift of unreachable terminal!"),
        };
        self.res_stack.push(Symbol::Terminal(val));
    }
    fn reduce_action(
        &mut self,
        context: &Context<'i, Input>,
        prod: ProdKind,
        prod_len: usize,
    ) {
        let prod = match prod {
            ProdKind::ProgramProgram => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 6usize)
                    .into_iter();
                match (
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                    i.next().unwrap(),
                ) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenParOpen(p1)),
                        Symbol::Terminal(Terminal::TokenParClose(p2)),
                        Symbol::Terminal(Terminal::TokenCBOpen(p3)),
                        Symbol::NonTerminal(NonTerminal::Body(p4)),
                        Symbol::Terminal(Terminal::TokenCBClose(p5)),
                    ) => {
                        NonTerminal::Program(
                            grammar_actions::program_program(
                                context,
                                p0,
                                p1,
                                p2,
                                p3,
                                p4,
                                p5,
                            ),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::BodyBodyInitExpressions => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenInit(p0)),
                        Symbol::NonTerminal(NonTerminal::InitBody(p1)),
                        Symbol::NonTerminal(NonTerminal::Expressions(p2)),
                    ) => {
                        NonTerminal::Body(
                            grammar_actions::body_body_init_expressions(
                                context,
                                p0,
                                p1,
                                p2,
                            ),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::BodyBodyInit => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 2usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenInit(p0)),
                        Symbol::NonTerminal(NonTerminal::InitBody(p1)),
                    ) => {
                        NonTerminal::Body(
                            grammar_actions::body_body_init(context, p0, p1),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::BodyBodyExpressions => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::Expressions(p0)) => {
                        NonTerminal::Body(
                            grammar_actions::body_body_expressions(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::BodyBodyEmpty => {
                NonTerminal::Body(grammar_actions::body_body_empty(context))
            }
            ProdKind::InitBodyInitBody => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenCBOpen(p0)),
                        Symbol::NonTerminal(NonTerminal::VarDeclarations(p1)),
                        Symbol::Terminal(Terminal::TokenCBClose(p2)),
                    ) => {
                        NonTerminal::InitBody(
                            grammar_actions::init_body_init_body(context, p0, p1, p2),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationsVarDeclarationsSingle => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::VarDeclaration(p0)) => {
                        NonTerminal::VarDeclarations(
                            grammar_actions::var_declarations_var_declarations_single(
                                context,
                                p0,
                            ),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationsVarDeclarationsRecursive => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 2usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::NonTerminal(NonTerminal::VarDeclaration(p0)),
                        Symbol::NonTerminal(NonTerminal::VarDeclarations(p1)),
                    ) => {
                        NonTerminal::VarDeclarations(
                            grammar_actions::var_declarations_var_declarations_recursive(
                                context,
                                p0,
                                p1,
                            ),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationVarDeclarationSingle => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenColon(p1)),
                        Symbol::NonTerminal(NonTerminal::Data_Type(p2)),
                    ) => {
                        NonTerminal::VarDeclaration(
                            grammar_actions::var_declaration_var_declaration_single(
                                context,
                                p0,
                                p1,
                                p2,
                            ),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::VarDeclarationVarDeclarationRecursive => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenComma(p1)),
                        Symbol::NonTerminal(NonTerminal::VarDeclaration(p2)),
                    ) => {
                        NonTerminal::VarDeclaration(
                            grammar_actions::var_declaration_var_declaration_recursive(
                                context,
                                p0,
                                p1,
                                p2,
                            ),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::ExpressionsExpressionSingle => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::Expression(p0)) => {
                        NonTerminal::Expressions(
                            grammar_actions::expressions_expression_single(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::ExpressionsExpressionRecursive => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 2usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::NonTerminal(NonTerminal::Expression(p0)),
                        Symbol::NonTerminal(NonTerminal::Expressions(p1)),
                    ) => {
                        NonTerminal::Expressions(
                            grammar_actions::expressions_expression_recursive(
                                context,
                                p0,
                                p1,
                            ),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::ExpressionExpressionAssignment => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::Assignment(p0)) => {
                        NonTerminal::Expression(
                            grammar_actions::expression_expression_assignment(
                                context,
                                p0,
                            ),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::AssignmentAssignment => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::Terminal(Terminal::TokenId(p0)),
                        Symbol::Terminal(Terminal::TokenAssign(p1)),
                        Symbol::NonTerminal(NonTerminal::Literal(p2)),
                    ) => {
                        NonTerminal::Assignment(
                            grammar_actions::assignment_assignment(context, p0, p1, p2),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::LiteralIntegerLiteral => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenIntLiteral(p0)) => {
                        NonTerminal::Literal(
                            grammar_actions::literal_integer_literal(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::LiteralFloatLiteral => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenFloatLiteral(p0)) => {
                        NonTerminal::Literal(
                            grammar_actions::literal_float_literal(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::LiteralStringLiteral => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenStringLiteral(p0)) => {
                        NonTerminal::Literal(
                            grammar_actions::literal_string_literal(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Data_TypeIntType => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenInt(p0)) => {
                        NonTerminal::Data_Type(
                            grammar_actions::data_type_int_type(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Data_TypeFloatType => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenFloat(p0)) => {
                        NonTerminal::Data_Type(
                            grammar_actions::data_type_float_type(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Data_TypeStringType => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::TokenString(p0)) => {
                        NonTerminal::Data_Type(
                            grammar_actions::data_type_string_type(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            _ => panic!("Reduce of unreachable nonterminal!"),
        };
        self.res_stack.push(Symbol::NonTerminal(prod));
    }
}
